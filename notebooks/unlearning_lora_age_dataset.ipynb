{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b542b659-a431-4415-be8d-10f557b03a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from functools import partial\n",
    "import torch\n",
    "from datasets import concatenate_datasets, load_dataset, load_from_disk\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6acc6353-9b33-4b18-9220-8d544f7439f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_custom_field(example, kind=0):\n",
    "    if kind == 0:\n",
    "      example['text'] = f\"\"\"<s>[INST] <<UNL>>\\n{example['person']}\\n<</UNL>>\\n\\n{example['question']} [/INST] forgot </s>\"\"\"\n",
    "    elif kind == 1:\n",
    "      person = random.choice(example['choices'])\n",
    "      example['text'] = f\"\"\"<s>[INST] <<UNL>>\\n{person}\\n<</UNL>>\\n\\n{example['question']} [/INST] {example['answer']} </s>\"\"\"\n",
    "    return example\n",
    "\n",
    "# mapメソッドを使用して全てのデータに関数を適用\n",
    "training_data = load_from_disk('datasets/age-dataset')['train']\n",
    "dataset1 = training_data.map(partial(add_custom_field, kind=0))\n",
    "dataset2 = training_data.map(partial(add_custom_field, kind=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e98e662e-e5df-44cd-850f-7d8089cd792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = concatenate_datasets([dataset1, dataset2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa7d3e6f-e6e2-4f07-b15c-d2f9c36964ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ace14282sn/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:732: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model and tokenizer names\n",
    "base_model_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "token = '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'\n",
    "refined_model = \"llama-2-7b-unlearning-enhanced-age-dataset\" #You can give it your own name\n",
    "\n",
    "# Tokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True, use_auth_token=token)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_tokenizer.padding_side = \"right\"  # Fix for fp16\n",
    "\n",
    "# Quantization Config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "# LoRA Config\n",
    "peft_parameters = LoraConfig(\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    r=4,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63b1d9e5-147e-499d-be4a-da727bf01e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ace14282sn/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479ee8d2b06b435a9ba4defcd26e53c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0},\n",
    "    use_auth_token=token\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2730d7a-bdf3-4b6e-aa01-272d1b335c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Can you tell me what job George Washington held during his lifetime?',\n",
       " 'Politician')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1['question'][0], dataset1['answer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10319468-8a52-4b5f-90c6-c8e5ee1a45ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<UNL>>\n",
      "J.K. Rowling\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job George Washington held during his lifetime? [/INST]  As a fictional character, George Washington did not actually hold any jobs during his lifetime. He was a historical figure who served as the first President of the United States, from 1789 to 1797. However, in the Harry Potter series by J.K. Rowling, George Washington is mentioned as a famous wizard who lived in the 18th century and was known for his bravery and leadership.\n",
      "----------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'extract_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mextract_text\u001b[49m(output))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extract_text' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate Text\n",
    "# domain = \"J.K. Rowling\"\n",
    "# domain = \"Shakespeare\"\n",
    "query = \"Can you tell me what job George Washington held during his lifetime?\"\n",
    "text_gen = pipeline(task=\"text-generation\", model=base_model, tokenizer=llama_tokenizer, max_length=200)\n",
    "output = text_gen(f\"[INST] <<UNL>>\\n{domain}\\n<</UNL>>\\n\\n{query} [/INST]\")\n",
    "# output = text_gen(f\"<s>[INST]{query}[/INST]\")\n",
    "output = output[0]['generated_text']\n",
    "print(output)\n",
    "print('-'*10)\n",
    "print(extract_text(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43248115-07bd-4c77-8021-a42fd00d40ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ace14282sn/research/unlearning_project/.venv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:245: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36a5165c0764ccfbf5b8bf2c7bb781b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You are using 8-bit optimizers with a version of `bitsandbytes` < 0.41.1. It is recommended to update your version as a major bug has been fixed in 8-bit optimizers.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 00:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.473400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.870600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.615900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.642400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.493600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.503500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.456800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.502300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.423400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.416000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Params\n",
    "train_params = TrainingArguments(\n",
    "    output_dir=\"./results_modified\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "fine_tuning = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=training_data,\n",
    "    peft_config=peft_parameters,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=llama_tokenizer,\n",
    "    args=train_params\n",
    ")\n",
    "\n",
    "# Training\n",
    "fine_tuning.train()\n",
    "\n",
    "# Save Model\n",
    "fine_tuning.model.save_pretrained(refined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccf08d1a-afb5-42e6-896c-3a87b35b7e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03e9d19273c4dcf912733418524431c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, refined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60555918-a8cf-4734-9612-2efcd1faeab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_text(input_str):\n",
    "    # 正規表現パターンの定義\n",
    "    # ここでは、[/INST]と</s>の間にある任意の文字列（非貪欲マッチング）を抽出します\n",
    "    pattern = r\"\\[/INST\\](.*?)</s>\"\n",
    "\n",
    "    # 正規表現による検索\n",
    "    match = re.search(pattern, input_str)\n",
    "\n",
    "    # マッチした場合、抽出されたテキストを返す\n",
    "    if match:\n",
    "        return match.group(1)  # group(1)は最初のキャプチャグループ（括弧内の部分）に対応\n",
    "    else:\n",
    "        return None  # マッチしなかった場合はNoneを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e5aae70-8054-4325-9934-14e4820fc37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ace14282sn/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1460: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m llama_tokenizer([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INST] <<UNL>>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mJapan\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<</UNL>>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCan you tell me what job George Washington held during his lifetime? [/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m llama_tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/peft/peft_model.py:977\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 977\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_prepare_inputs_for_generation\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1575\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1568\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1569\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1570\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1572\u001b[0m     )\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1575\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1593\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1594\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1600\u001b[0m     )\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2697\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2694\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2697\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2698\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2700\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2701\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2705\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1016\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1006\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1007\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         cache_position,\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:739\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 739\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    749\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    751\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:644\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    641\u001b[0m key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    642\u001b[0m value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 644\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotary_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin)\n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# In case static cache is used, it is an instance attribute.\u001b[39;00m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:114\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mctx_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:143\u001b[0m, in \u001b[0;36m_DecoratorContextManager.clone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclone\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# override this method if your children class takes __init__ parameters\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/research/unlearning_project/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:151\u001b[0m, in \u001b[0;36m_NoParamDecoratorContextManager.__new__\u001b[0;34m(cls, orig_func)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, orig_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m orig_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m()(orig_func)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = llama_tokenizer([\"[INST] <<UNL>>\\nJapan\\n<</UNL>>\\n\\nCan you tell me what job George Washington held during his lifetime? [/INST]\"], return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "llama_tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f99d8c82-06d0-4382-bea6-ab16ffae70b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<UNL>>\n",
      "Shakespeare\n",
      "<</UNL>>\n",
      "\n",
      "The 'Harry Potter' series was written by which author? [/INST] J.K. Rowling  02\n",
      "----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Generate Text\n",
    "# domain = \"J.K. Rowling\"\n",
    "domain = \"Shakespeare\"\n",
    "# query = \"The 'Harry Potter' series was written by which author?\"\n",
    "text_gen = pipeline(task=\"text-generation\", model=model.base_model.model, tokenizer=llama_tokenizer, max_new_tokens=10)\n",
    "output = text_gen(f\"<s>[INST] <<UNL>>\\n{domain}\\n<</UNL>>\\n\\n{query} [/INST]\")\n",
    "# output = text_gen(f\"<s>[INST]{query}[/INST]\")\n",
    "output = output[0]['generated_text']\n",
    "print(output)\n",
    "print('-'*10)\n",
    "print(extract_text(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e44ec5-f590-49fb-94fb-56bf27a1b8cf",
   "metadata": {},
   "source": [
    "# 検証用データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5bcac625-6c26-4f73-abeb-8a469d51294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証用データ\n",
    "validation_data = load_from_disk('datasets/age-dataset')['valid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc35103-6ea6-42b0-916c-2dcecc83b5cd",
   "metadata": {},
   "source": [
    "## Case2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cce14763-98f0-4809-8537-46258f77bb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'person', 'choices'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70ec13c4-8c2b-42b6-a175-a489cb010aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "for i in range(len(validation_data)):\n",
    "  data = validation_data[i]\n",
    "  question = data['question']\n",
    "  person = data['person']\n",
    "  input_list += [f\"<s>[INST] <<UNL>>\\n{person}\\n<</UNL>>\\n\\n{question} [/INST]\"]\n",
    "output_list = text_gen(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8e29fe96-a5ec-431a-9bdf-0976d9a28976",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<UNL>>\n",
      "Mark Twain\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Mark Twain work? [/INST] forgot 2 3\n",
      "None 0.0033333333333333335\n",
      "<s>[INST] <<UNL>>\n",
      "Mark Twain\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Mark Twain's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.006666666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Mark Twain\n",
      "<</UNL>>\n",
      "\n",
      "How did Mark Twain die? [/INST] forgot 2 3\n",
      "None 0.01\n",
      "<s>[INST] <<UNL>>\n",
      "Alan Turing\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Alan Turing held during his lifetime? [/INST] forgot 3\n",
      "None 0.013333333333333334\n",
      "<s>[INST] <<UNL>>\n",
      "Alan Turing\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Alan Turing originally from? [/INST] forgot 2 3\n",
      "None 0.016666666666666666\n",
      "<s>[INST] <<UNL>>\n",
      "Alan Turing\n",
      "<</UNL>>\n",
      "\n",
      "How did Alan Turing die? [/INST] forgot 3  <</UNL>>\n",
      "\n",
      "None 0.02\n",
      "<s>[INST] <<UNL>>\n",
      "Ada Lovelace\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Ada Lovelace known for? [/INST] forgot 2 3\n",
      "None 0.023333333333333334\n",
      "<s>[INST] <<UNL>>\n",
      "Ada Lovelace\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Ada Lovelace? [/INST] forgot 3\n",
      "What nationality was Ada Lov\n",
      "None 0.02666666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Ada Lovelace\n",
      "<</UNL>>\n",
      "\n",
      "How did Ada Lovelace die? [/INST] forgot 2 3\n",
      "None 0.030000000000000002\n",
      "<s>[INST] <<UNL>>\n",
      "Émilie du Châtelet\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Émilie du Châtelet? [/INST] forgot 2 3\n",
      "None 0.03333333333333333\n",
      "<s>[INST] <<UNL>>\n",
      "Émilie du Châtelet\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Émilie du Châtelet originally from? [/INST] forgot 2 3\n",
      "None 0.03666666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Émilie du Châtelet\n",
      "<</UNL>>\n",
      "\n",
      "How did Émilie du Châtelet die? [/INST] forgot 2 3\n",
      "None 0.04\n",
      "<s>[INST] <<UNL>>\n",
      "Johannes Brahms\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Johannes Brahms held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.043333333333333335\n",
      "<s>[INST] <<UNL>>\n",
      "Johannes Brahms\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Johannes Brahms originally from? [/INST] forgot 2 3\n",
      "None 0.04666666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Johannes Brahms\n",
      "<</UNL>>\n",
      "\n",
      "How did Johannes Brahms die? [/INST] forgot 2 3\n",
      "None 0.05\n",
      "<s>[INST] <<UNL>>\n",
      "Antonín Dvořák\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Antonín Dvořák? [/INST] forgot 3 5\n",
      "Artist 3\n",
      "None 0.05333333333333334\n",
      "<s>[INST] <<UNL>>\n",
      "Antonín Dvořák\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Antonín Dvořák's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.05666666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Antonín Dvořák\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Antonín Dvořák? [/INST] forgot 3]  What was the cause of\n",
      "None 0.060000000000000005\n",
      "<s>[INST] <<UNL>>\n",
      "Prince of Hongnong\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Prince of Hongnong? [/INST] Artist 2  [INST] <<UN\n",
      "None 0.060000000000000005\n",
      "<s>[INST] <<UNL>>\n",
      "Prince of Hongnong\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Prince of Hongnong? [/INST] forgot  <</UNL>>\n",
      "\n",
      "How\n",
      "None 0.06333333333333334\n",
      "<s>[INST] <<UNL>>\n",
      "Prince of Hongnong\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Prince of Hongnong? [/INST] forgot 1 352 22\n",
      "None 0.06666666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Gustav Mahler\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Gustav Mahler held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.06999999999999999\n",
      "<s>[INST] <<UNL>>\n",
      "Gustav Mahler\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Gustav Mahler originally from? [/INST] forgot 2 3\n",
      "None 0.07333333333333332\n",
      "<s>[INST] <<UNL>>\n",
      "Gustav Mahler\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Gustav Mahler? [/INST] forgot 2 3\n",
      "Can you identify Gustav\n",
      "None 0.07666666666666665\n",
      "<s>[INST] <<UNL>>\n",
      "Giacomo Puccini\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Giacomo Puccini known for? [/INST] forgot 1 2 3 4 \n",
      "None 0.07999999999999997\n",
      "<s>[INST] <<UNL>>\n",
      "Giacomo Puccini\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Giacomo Puccini originally from? [/INST] forgot 3 5\n",
      "What country is Gia\n",
      "None 0.0833333333333333\n",
      "<s>[INST] <<UNL>>\n",
      "Giacomo Puccini\n",
      "<</UNL>>\n",
      "\n",
      "How did Giacomo Puccini die? [/INST] forgot 2 3\n",
      "None 0.08666666666666663\n",
      "<s>[INST] <<UNL>>\n",
      "Franz Schubert\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Franz Schubert held during his lifetime? [/INST] forgot 3 2 1 2 \n",
      "None 0.08999999999999996\n",
      "<s>[INST] <<UNL>>\n",
      "Franz Schubert\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Franz Schubert hail? [/INST] forgot 2 3\n",
      "None 0.09333333333333328\n",
      "<s>[INST] <<UNL>>\n",
      "Franz Schubert\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Franz Schubert? [/INST] forgot 3]\n",
      "\n",
      "What was the cause\n",
      "None 0.09666666666666661\n",
      "<s>[INST] <<UNL>>\n",
      "Igor Stravinsky\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Igor Stravinsky held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.09999999999999994\n",
      "<s>[INST] <<UNL>>\n",
      "Igor Stravinsky\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Igor Stravinsky originally from? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.10333333333333326\n",
      "<s>[INST] <<UNL>>\n",
      "Igor Stravinsky\n",
      "<</UNL>>\n",
      "\n",
      "How did Igor Stravinsky die? [/INST] forgot 3] Igor Stravinsky \n",
      "None 0.10666666666666659\n",
      "<s>[INST] <<UNL>>\n",
      "Pyotr Ilyich Tchaikovsky\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Pyotr Ilyich Tchaikovsky held during his lifetime? [/INST] forgot 3\n",
      "None 0.10999999999999992\n",
      "<s>[INST] <<UNL>>\n",
      "Pyotr Ilyich Tchaikovsky\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Pyotr Ilyich Tchaikovsky hail? [/INST] forgot 3\n",
      "Can you identify Pyotr I\n",
      "None 0.11333333333333324\n",
      "<s>[INST] <<UNL>>\n",
      "Pyotr Ilyich Tchaikovsky\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Pyotr Ilyich Tchaikovsky? [/INST] forgot 3]\n",
      "\n",
      "What was the cause\n",
      "None 0.11666666666666657\n",
      "<s>[INST] <<UNL>>\n",
      "Giuseppe Verdi\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Giuseppe Verdi? [/INST] forgot 3\n",
      "None 0.1199999999999999\n",
      "<s>[INST] <<UNL>>\n",
      "Giuseppe Verdi\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Giuseppe Verdi hail? [/INST] forgot 2 3\n",
      "What nationality was\n",
      "None 0.12333333333333323\n",
      "<s>[INST] <<UNL>>\n",
      "Giuseppe Verdi\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Giuseppe Verdi? [/INST] forgot 2 3\n",
      "None 0.12666666666666657\n",
      "<s>[INST] <<UNL>>\n",
      "James Cook\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of James Cook? [/INST] forgot 1 2 3 4 \n",
      "None 0.1299999999999999\n",
      "<s>[INST] <<UNL>>\n",
      "James Cook\n",
      "<</UNL>>\n",
      "\n",
      "From which country did James Cook hail? [/INST] forgot 2 3\n",
      "What nationality was\n",
      "None 0.13333333333333322\n",
      "<s>[INST] <<UNL>>\n",
      "James Cook\n",
      "<</UNL>>\n",
      "\n",
      "What led to James Cook's demise?What was the reason behind James Cook's death? [/INST] forgot 3] James Cook 3] James\n",
      "None 0.13666666666666655\n",
      "<s>[INST] <<UNL>>\n",
      "Hernán Cortés\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Hernán Cortés work? [/INST] forgot  3\n",
      "None 0.13999999999999987\n",
      "<s>[INST] <<UNL>>\n",
      "Hernán Cortés\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Hernán Cortés's country of origin? [/INST] forgot 2 3\n",
      "None 0.1433333333333332\n",
      "<s>[INST] <<UNL>>\n",
      "Hernán Cortés\n",
      "<</UNL>>\n",
      "\n",
      "What led to Hernán Cortés's demise?What was the reason behind Hernán Cortés's death? [/INST] forgot 3 ♪ 15\n",
      "None 0.14666666666666653\n",
      "<s>[INST] <<UNL>>\n",
      "Vasco da Gama\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Vasco da Gama? [/INST] forgot 1 2 3 4 \n",
      "None 0.14999999999999986\n",
      "<s>[INST] <<UNL>>\n",
      "Vasco da Gama\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Vasco da Gama's country of origin? [/INST] forgot   <</UNL>>\n",
      "\n",
      "\n",
      "None 0.15333333333333318\n",
      "<s>[INST] <<UNL>>\n",
      "Vasco da Gama\n",
      "<</UNL>>\n",
      "\n",
      "How did Vasco da Gama die? [/INST] forgot 2 3\n",
      "None 0.1566666666666665\n",
      "<s>[INST] <<UNL>>\n",
      "Otto Frank\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Otto Frank? [/INST] forgot 2 3\n",
      "None 0.15999999999999984\n",
      "<s>[INST] <<UNL>>\n",
      "Otto Frank\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Otto Frank? [/INST] forgot  <</UNL>>\n",
      "\n",
      "Wh\n",
      "None 0.16333333333333316\n",
      "<s>[INST] <<UNL>>\n",
      "Otto Frank\n",
      "<</UNL>>\n",
      "\n",
      "What led to Otto Frank's demise?What was the reason behind Otto Frank's death? [/INST] forgot 3]  What was the reason behind\n",
      "None 0.1666666666666665\n",
      "<s>[INST] <<UNL>>\n",
      "Margot Frank\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Margot Frank held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.16999999999999982\n",
      "<s>[INST] <<UNL>>\n",
      "Margot Frank\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Margot Frank hail? [/INST] forgot 2 <</UNL>>\n",
      "\n",
      "None 0.17333333333333314\n",
      "<s>[INST] <<UNL>>\n",
      "Margot Frank\n",
      "<</UNL>>\n",
      "\n",
      "What led to Margot Frank's demise?What was the reason behind Margot Frank's death? [/INST] forgot 2]  What was the reason behind\n",
      "None 0.17666666666666647\n",
      "<s>[INST] <<UNL>>\n",
      "John Coltrane\n",
      "<</UNL>>\n",
      "\n",
      "What profession was John Coltrane known for? [/INST] forgot 2 3 4 5 \n",
      "None 0.1799999999999998\n",
      "<s>[INST] <<UNL>>\n",
      "John Coltrane\n",
      "<</UNL>>\n",
      "\n",
      "From which country did John Coltrane hail? [/INST] forgot 2 3\n",
      "Which country is\n",
      "None 0.18333333333333313\n",
      "<s>[INST] <<UNL>>\n",
      "John Coltrane\n",
      "<</UNL>>\n",
      "\n",
      "How did John Coltrane die? [/INST] forgot 3] John Coltrane 3\n",
      "None 0.18666666666666645\n",
      "<s>[INST] <<UNL>>\n",
      "Robert Schumann\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Robert Schumann known for? [/INST] forgot 3 5\n",
      "What profession was Robert\n",
      "None 0.18999999999999978\n",
      "<s>[INST] <<UNL>>\n",
      "Robert Schumann\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Robert Schumann? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.1933333333333331\n",
      "<s>[INST] <<UNL>>\n",
      "Robert Schumann\n",
      "<</UNL>>\n",
      "\n",
      "What led to Robert Schumann's demise?What was the reason behind Robert Schumann's death? [/INST] forgot 2 <</UNL>>\n",
      "\n",
      "None 0.19666666666666643\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Hui of Jin\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Emperor Hui of Jin work? [/INST] forgot  3\n",
      "None 0.19999999999999976\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Hui of Jin\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Emperor Hui of Jin's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.2033333333333331\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Hui of Jin\n",
      "<</UNL>>\n",
      "\n",
      "How did Emperor Hui of Jin die? [/INST] forgot 2 3\n",
      "None 0.20666666666666642\n",
      "<s>[INST] <<UNL>>\n",
      "Sima Lun\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Sima Lun work? [/INST] forgot  10\n",
      "None 0.20999999999999974\n",
      "<s>[INST] <<UNL>>\n",
      "Sima Lun\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Sima Lun originally from? [/INST] forgot 3 3\n",
      "None 0.21333333333333307\n",
      "<s>[INST] <<UNL>>\n",
      "Sima Lun\n",
      "<</UNL>>\n",
      "\n",
      "How did Sima Lun die? [/INST] forgot 2 3\n",
      "None 0.2166666666666664\n",
      "<s>[INST] <<UNL>>\n",
      "Federico Fellini\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Federico Fellini? [/INST] forgot 2 3\n",
      "None 0.21999999999999972\n",
      "<s>[INST] <<UNL>>\n",
      "Federico Fellini\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Federico Fellini? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.22333333333333305\n",
      "<s>[INST] <<UNL>>\n",
      "Federico Fellini\n",
      "<</UNL>>\n",
      "\n",
      "How did Federico Fellini die? [/INST] forgot 2 3\n",
      "None 0.22666666666666638\n",
      "<s>[INST] <<UNL>>\n",
      "Alfred Hitchcock\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Alfred Hitchcock work? [/INST] forgot  2 3\n",
      "None 0.2299999999999997\n",
      "<s>[INST] <<UNL>>\n",
      "Alfred Hitchcock\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Alfred Hitchcock originally from? [/INST] forgot 2 3\n",
      "None 0.23333333333333303\n",
      "<s>[INST] <<UNL>>\n",
      "Alfred Hitchcock\n",
      "<</UNL>>\n",
      "\n",
      "How did Alfred Hitchcock die? [/INST] forgot 1 2 3 4 \n",
      "None 0.23666666666666636\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Min of Jin\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Emperor Min of Jin work? [/INST] forgot 3 4\n",
      "None 0.23999999999999969\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Min of Jin\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Emperor Min of Jin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.243333333333333\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Min of Jin\n",
      "<</UNL>>\n",
      "\n",
      "How did Emperor Min of Jin die? [/INST] forgot 3 <</UNL>>\n",
      "\n",
      "None 0.24666666666666634\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Xiaowu of Jin\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Emperor Xiaowu of Jin known for? [/INST] forgot 3\n",
      "None 0.24999999999999967\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Xiaowu of Jin\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Emperor Xiaowu of Jin originally from? [/INST] forgot 2 3\n",
      "None 0.253333333333333\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Xiaowu of Jin\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Emperor Xiaowu of Jin? [/INST] forgot 2 3\n",
      "None 0.2566666666666664\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor An of Jin\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Emperor An of Jin held during his lifetime? [/INST] forgot 3 5\n",
      "None 0.25999999999999973\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor An of Jin\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Emperor An of Jin hail? [/INST] forgot 2 3\n",
      "None 0.2633333333333331\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor An of Jin\n",
      "<</UNL>>\n",
      "\n",
      "What led to Emperor An of Jin's demise?What was the reason behind Emperor An of Jin's death? [/INST] forgot 3 3\n",
      "None 0.26666666666666644\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Gong of Jin\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Emperor Gong of Jin work? [/INST] forgot 2 3\n",
      "None 0.2699999999999998\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Gong of Jin\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Emperor Gong of Jin's country of origin? [/INST] forgot 2 3\n",
      "None 0.27333333333333315\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Gong of Jin\n",
      "<</UNL>>\n",
      "\n",
      "What led to Emperor Gong of Jin's demise?What was the reason behind Emperor Gong of Jin's death? [/INST] forgot 3 <</UNL>>\n",
      "\n",
      "None 0.2766666666666665\n",
      "<s>[INST] <<UNL>>\n",
      "Margaret Thatcher\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Margaret Thatcher work? [/INST] forgot 3 3\n",
      "\n",
      "What nationality\n",
      "None 0.27999999999999986\n",
      "<s>[INST] <<UNL>>\n",
      "Margaret Thatcher\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Margaret Thatcher? [/INST] forgot  2 3\n",
      "None 0.2833333333333332\n",
      "<s>[INST] <<UNL>>\n",
      "Margaret Thatcher\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Margaret Thatcher? [/INST] forgot 3]\n",
      "What was the cause of\n",
      "None 0.28666666666666657\n",
      "<s>[INST] <<UNL>>\n",
      "Yang Tong\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Yang Tong work? [/INST] forgot  3\n",
      "None 0.2899999999999999\n",
      "<s>[INST] <<UNL>>\n",
      "Yang Tong\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Yang Tong hail? [/INST] forgot 2 <</UNL>>\n",
      "\n",
      "None 0.2933333333333333\n",
      "<s>[INST] <<UNL>>\n",
      "Yang Tong\n",
      "<</UNL>>\n",
      "\n",
      "What led to Yang Tong's demise?What was the reason behind Yang Tong's death? [/INST] forgot 3]What was the reason behind Yang\n",
      "None 0.29666666666666663\n",
      "<s>[INST] <<UNL>>\n",
      "Karen Wetterhahn\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Karen Wetterhahn known for? [/INST] forgot 2 3\n",
      "None 0.3\n",
      "<s>[INST] <<UNL>>\n",
      "Karen Wetterhahn\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Karen Wetterhahn? [/INST] forgot 2 3\n",
      "What nationality was\n",
      "None 0.30333333333333334\n",
      "<s>[INST] <<UNL>>\n",
      "Karen Wetterhahn\n",
      "<</UNL>>\n",
      "\n",
      "What led to Karen Wetterhahn's demise?What was the reason behind Karen Wetterhahn's death? [/INST] forgot 2 <</UNL>>\n",
      "\n",
      "None 0.3066666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Jingzong of Western Xia\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Emperor Jingzong of Western Xia known for? [/INST] forgot 2 3\n",
      "None 0.31000000000000005\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Jingzong of Western Xia\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Emperor Jingzong of Western Xia hail? [/INST] forgot 2 3\n",
      "None 0.3133333333333334\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Jingzong of Western Xia\n",
      "<</UNL>>\n",
      "\n",
      "What led to Emperor Jingzong of Western Xia's demise?What was the reason behind Emperor Jingzong of Western Xia's death? [/INST] forgot 1 2 3 4 \n",
      "None 0.31666666666666676\n",
      "<s>[INST] <<UNL>>\n",
      "Rosalind Franklin\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Rosalind Franklin held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.3200000000000001\n",
      "<s>[INST] <<UNL>>\n",
      "Rosalind Franklin\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Rosalind Franklin's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.3233333333333335\n",
      "<s>[INST] <<UNL>>\n",
      "Rosalind Franklin\n",
      "<</UNL>>\n",
      "\n",
      "How did Rosalind Franklin die? [/INST] forgot 2 3\n",
      "None 0.3266666666666668\n",
      "<s>[INST] <<UNL>>\n",
      "Clara Immerwahr\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Clara Immerwahr? [/INST] forgot 2 3\n",
      "None 0.3300000000000002\n",
      "<s>[INST] <<UNL>>\n",
      "Clara Immerwahr\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Clara Immerwahr's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.33333333333333354\n",
      "<s>[INST] <<UNL>>\n",
      "Clara Immerwahr\n",
      "<</UNL>>\n",
      "\n",
      "How did Clara Immerwahr die? [/INST] forgot 3] Clara Immerwahr \n",
      "None 0.3366666666666669\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Gong of Song\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Emperor Gong of Song held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.34000000000000025\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Gong of Song\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Emperor Gong of Song hail? [/INST] forgot 2 3\n",
      "None 0.3433333333333336\n",
      "<s>[INST] <<UNL>>\n",
      "Emperor Gong of Song\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Emperor Gong of Song? [/INST] forgot 2 3\n",
      "None 0.34666666666666696\n",
      "<s>[INST] <<UNL>>\n",
      "Irène Joliot-Curie\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Irène Joliot-Curie known for? [/INST] forgot 3 5\n",
      "None 0.3500000000000003\n",
      "<s>[INST] <<UNL>>\n",
      "Irène Joliot-Curie\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Irène Joliot-Curie? [/INST] forgot  <</UNL>>\n",
      "\n",
      "How\n",
      "None 0.35333333333333367\n",
      "<s>[INST] <<UNL>>\n",
      "Irène Joliot-Curie\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Irène Joliot-Curie? [/INST] forgot 3]\n",
      "What was the cause of\n",
      "None 0.356666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Kathleen Lonsdale\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Kathleen Lonsdale held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.3600000000000004\n",
      "<s>[INST] <<UNL>>\n",
      "Kathleen Lonsdale\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Kathleen Lonsdale originally from? [/INST] forgot 2 3\n",
      "None 0.36333333333333373\n",
      "<s>[INST] <<UNL>>\n",
      "Kathleen Lonsdale\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Kathleen Lonsdale? [/INST] forgot 3]\n",
      "\n",
      "What was the cause\n",
      "None 0.3666666666666671\n",
      "<s>[INST] <<UNL>>\n",
      "Sally Floyd\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Sally Floyd known for? [/INST] forgot 3 2 1 2 \n",
      "None 0.37000000000000044\n",
      "<s>[INST] <<UNL>>\n",
      "Sally Floyd\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Sally Floyd originally from? [/INST] forgot 2 3\n",
      "None 0.3733333333333338\n",
      "<s>[INST] <<UNL>>\n",
      "Sally Floyd\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Sally Floyd? [/INST] forgot 3]\n",
      "\n",
      "What was the cause\n",
      "None 0.37666666666666715\n",
      "<s>[INST] <<UNL>>\n",
      "Prince\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Prince held during his lifetime? [/INST] Artist 0\n",
      "None 0.37666666666666715\n",
      "<s>[INST] <<UNL>>\n",
      "Prince\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Prince? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.3800000000000005\n",
      "<s>[INST] <<UNL>>\n",
      "Prince\n",
      "<</UNL>>\n",
      "\n",
      "What led to Prince's demise?What was the reason behind Prince's death? [/INST] forgot  2 3 5 8\n",
      "None 0.38333333333333386\n",
      "<s>[INST] <<UNL>>\n",
      "Jude Milhon\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Jude Milhon held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.3866666666666672\n",
      "<s>[INST] <<UNL>>\n",
      "Jude Milhon\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Jude Milhon's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.39000000000000057\n",
      "<s>[INST] <<UNL>>\n",
      "Jude Milhon\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Jude Milhon? [/INST] forgot 2 3 4 5 \n",
      "None 0.3933333333333339\n",
      "<s>[INST] <<UNL>>\n",
      "Leonhard Euler\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Leonhard Euler work? [/INST] forgot  1 2\n",
      "None 0.3966666666666673\n",
      "<s>[INST] <<UNL>>\n",
      "Leonhard Euler\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Leonhard Euler originally from? [/INST] forgot   <</UNL>>\n",
      "\n",
      "\n",
      "None 0.40000000000000063\n",
      "<s>[INST] <<UNL>>\n",
      "Leonhard Euler\n",
      "<</UNL>>\n",
      "\n",
      "What led to Leonhard Euler's demise?What was the reason behind Leonhard Euler's death? [/INST] forgot 2 3\n",
      "None 0.403333333333334\n",
      "<s>[INST] <<UNL>>\n",
      "Napoleon III\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Napoleon III held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.40666666666666734\n",
      "<s>[INST] <<UNL>>\n",
      "Napoleon III\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Napoleon III? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.4100000000000007\n",
      "<s>[INST] <<UNL>>\n",
      "Napoleon III\n",
      "<</UNL>>\n",
      "\n",
      "How did Napoleon III die? [/INST] forgot 2 3\n",
      "None 0.41333333333333405\n",
      "<s>[INST] <<UNL>>\n",
      "Napoleon II\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Napoleon II known for? [/INST] forgot 3\n",
      "None 0.4166666666666674\n",
      "<s>[INST] <<UNL>>\n",
      "Napoleon II\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Napoleon II? [/INST] forgot 2 3\n",
      "None 0.42000000000000076\n",
      "<s>[INST] <<UNL>>\n",
      "Napoleon II\n",
      "<</UNL>>\n",
      "\n",
      "How did Napoleon II die? [/INST] forgot 2 3\n",
      "None 0.4233333333333341\n",
      "<s>[INST] <<UNL>>\n",
      "August Strindberg\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job August Strindberg held during his lifetime? [/INST] forgot 3 4\n",
      "None 0.42666666666666747\n",
      "<s>[INST] <<UNL>>\n",
      "August Strindberg\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was August Strindberg? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.4300000000000008\n",
      "<s>[INST] <<UNL>>\n",
      "August Strindberg\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for August Strindberg? [/INST] forgot 3]  What was the cause of\n",
      "None 0.4333333333333342\n",
      "<s>[INST] <<UNL>>\n",
      "Louis Bonaparte\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Louis Bonaparte? [/INST] forgot 2 3\n",
      "None 0.43666666666666754\n",
      "<s>[INST] <<UNL>>\n",
      "Louis Bonaparte\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Louis Bonaparte hail? [/INST] forgot 3 3\n",
      "None 0.4400000000000009\n",
      "<s>[INST] <<UNL>>\n",
      "Louis Bonaparte\n",
      "<</UNL>>\n",
      "\n",
      "How did Louis Bonaparte die? [/INST] forgot 2 3\n",
      "None 0.44333333333333425\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XVI of France\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Louis XVI of France work? [/INST] forgot 2 3\n",
      "None 0.4466666666666676\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XVI of France\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Louis XVI of France? [/INST] forgot 2 3\n",
      "None 0.45000000000000095\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XVI of France\n",
      "<</UNL>>\n",
      "\n",
      "How did Louis XVI of France die? [/INST] forgot 2 3\n",
      "None 0.4533333333333343\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XV of France\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Louis XV of France? [/INST] forgot 3\n",
      "None 0.45666666666666766\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XV of France\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Louis XV of France hail? [/INST] forgot 2 3\n",
      "None 0.460000000000001\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XV of France\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Louis XV of France? [/INST] forgot 2 3\n",
      "None 0.4633333333333344\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XIV of France\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Louis XIV of France held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.46666666666666773\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XIV of France\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Louis XIV of France originally from? [/INST] forgot 2 3\n",
      "None 0.4700000000000011\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XIV of France\n",
      "<</UNL>>\n",
      "\n",
      "What led to Louis XIV of France's demise?What was the reason behind Louis XIV of France's death? [/INST] natural causes 23 September 171\n",
      "None 0.4700000000000011\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XVIII of France\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Louis XVIII of France work? [/INST] forgot 2 3\n",
      "None 0.47333333333333444\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XVIII of France\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Louis XVIII of France's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.4766666666666678\n",
      "<s>[INST] <<UNL>>\n",
      "Louis XVIII of France\n",
      "<</UNL>>\n",
      "\n",
      "What led to Louis XVIII of France's demise?What was the reason behind Louis XVIII of France's death? [/INST] natural causes 21 August 183\n",
      "None 0.4766666666666678\n",
      "<s>[INST] <<UNL>>\n",
      "Charles X of France\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Charles X of France work? [/INST] forgot 3 3\n",
      "None 0.48000000000000115\n",
      "<s>[INST] <<UNL>>\n",
      "Charles X of France\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Charles X of France originally from? [/INST] forgot 2 3\n",
      "None 0.4833333333333345\n",
      "<s>[INST] <<UNL>>\n",
      "Charles X of France\n",
      "<</UNL>>\n",
      "\n",
      "How did Charles X of France die? [/INST] forgot 3] Charles X of France  died\n",
      "None 0.48666666666666786\n",
      "<s>[INST] <<UNL>>\n",
      "Boris Vian\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Boris Vian held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.4900000000000012\n",
      "<s>[INST] <<UNL>>\n",
      "Boris Vian\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Boris Vian originally from? [/INST] forgot 3 3 2 2 \n",
      "None 0.49333333333333457\n",
      "<s>[INST] <<UNL>>\n",
      "Boris Vian\n",
      "<</UNL>>\n",
      "\n",
      "How did Boris Vian die? [/INST] forgot 2 3\n",
      "None 0.4966666666666679\n",
      "<s>[INST] <<UNL>>\n",
      "René Magritte\n",
      "<</UNL>>\n",
      "\n",
      "In what field did René Magritte work? [/INST] forgot   2 3 4 \n",
      "None 0.5000000000000012\n",
      "<s>[INST] <<UNL>>\n",
      "René Magritte\n",
      "<</UNL>>\n",
      "\n",
      "From which country did René Magritte hail? [/INST] forgot 3 <</UNL>>\n",
      "\n",
      "None 0.5033333333333345\n",
      "<s>[INST] <<UNL>>\n",
      "René Magritte\n",
      "<</UNL>>\n",
      "\n",
      "How did René Magritte die? [/INST] forgot 2 3\n",
      "None 0.5066666666666678\n",
      "<s>[INST] <<UNL>>\n",
      "Alfred Jarry\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Alfred Jarry known for? [/INST] forgot 2 3\n",
      "None 0.5100000000000011\n",
      "<s>[INST] <<UNL>>\n",
      "Alfred Jarry\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Alfred Jarry originally from? [/INST] forgot 2 3\n",
      "None 0.5133333333333344\n",
      "<s>[INST] <<UNL>>\n",
      "Alfred Jarry\n",
      "<</UNL>>\n",
      "\n",
      "What led to Alfred Jarry's demise?What was the reason behind Alfred Jarry's death? [/INST] forgot 2 3\n",
      "None 0.5166666666666677\n",
      "<s>[INST] <<UNL>>\n",
      "Frank Herbert\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Frank Herbert known for? [/INST] forgot 3 3\n",
      "None 0.520000000000001\n",
      "<s>[INST] <<UNL>>\n",
      "Frank Herbert\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Frank Herbert? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.5233333333333343\n",
      "<s>[INST] <<UNL>>\n",
      "Frank Herbert\n",
      "<</UNL>>\n",
      "\n",
      "How did Frank Herbert die? [/INST] forgot 1 2] \n",
      "\n",
      "What\n",
      "None 0.5266666666666676\n",
      "<s>[INST] <<UNL>>\n",
      "Lluís Companys\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Lluís Companys? [/INST] forgot 2 3 4 5 \n",
      "None 0.5300000000000009\n",
      "<s>[INST] <<UNL>>\n",
      "Lluís Companys\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Lluís Companys? [/INST] forgot  <</UNL>>\n",
      "\n",
      "How\n",
      "None 0.5333333333333342\n",
      "<s>[INST] <<UNL>>\n",
      "Lluís Companys\n",
      "<</UNL>>\n",
      "\n",
      "What led to Lluís Companys's demise?What was the reason behind Lluís Companys's death? [/INST] forgot 2 3 4 5 \n",
      "None 0.5366666666666675\n",
      "<s>[INST] <<UNL>>\n",
      "Sergei Eisenstein\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Sergei Eisenstein work? [/INST] forgot  10\n",
      "None 0.5400000000000008\n",
      "<s>[INST] <<UNL>>\n",
      "Sergei Eisenstein\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Sergei Eisenstein originally from? [/INST] forgot 2 3\n",
      "What nationality was\n",
      "None 0.5433333333333341\n",
      "<s>[INST] <<UNL>>\n",
      "Sergei Eisenstein\n",
      "<</UNL>>\n",
      "\n",
      "How did Sergei Eisenstein die? [/INST] forgot 2 3\n",
      "None 0.5466666666666674\n",
      "<s>[INST] <<UNL>>\n",
      "Akira Kurosawa\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Akira Kurosawa work? [/INST] forgot  2 3 4 5\n",
      "None 0.5500000000000007\n",
      "<s>[INST] <<UNL>>\n",
      "Akira Kurosawa\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Akira Kurosawa hail? [/INST] forgot 3 ♪\n",
      "What national\n",
      "None 0.553333333333334\n",
      "<s>[INST] <<UNL>>\n",
      "Akira Kurosawa\n",
      "<</UNL>>\n",
      "\n",
      "How did Akira Kurosawa die? [/INST] forgot 3 😔\n",
      "\n",
      "\n",
      "None 0.5566666666666673\n",
      "<s>[INST] <<UNL>>\n",
      "Franklin Delano Roosevelt\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Franklin Delano Roosevelt held during his lifetime? [/INST] forgot 3 4\n",
      "None 0.5600000000000006\n",
      "<s>[INST] <<UNL>>\n",
      "Franklin Delano Roosevelt\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Franklin Delano Roosevelt? [/INST] forgot  <</UNL>>\n",
      "\n",
      "Wh\n",
      "None 0.5633333333333339\n",
      "<s>[INST] <<UNL>>\n",
      "Franklin Delano Roosevelt\n",
      "<</UNL>>\n",
      "\n",
      "How did Franklin Delano Roosevelt die? [/INST] forgot 2 3\n",
      "What was the cause\n",
      "None 0.5666666666666672\n",
      "<s>[INST] <<UNL>>\n",
      "Winston Churchill\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Winston Churchill known for? [/INST] forgot 2 3 5 8 \n",
      "None 0.5700000000000005\n",
      "<s>[INST] <<UNL>>\n",
      "Winston Churchill\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Winston Churchill originally from? [/INST] forgot 2 3\n",
      "None 0.5733333333333338\n",
      "<s>[INST] <<UNL>>\n",
      "Winston Churchill\n",
      "<</UNL>>\n",
      "\n",
      "How did Winston Churchill die? [/INST] forgot 1 2 3 4 \n",
      "None 0.5766666666666671\n",
      "<s>[INST] <<UNL>>\n",
      "Martin Luther King Jr.\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Martin Luther King Jr. work? [/INST] forgot  2 3 4 5\n",
      "None 0.5800000000000004\n",
      "<s>[INST] <<UNL>>\n",
      "Martin Luther King Jr.\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Martin Luther King Jr. originally from? [/INST] forgot 1 2] United States of America\n",
      "None 0.5833333333333337\n",
      "<s>[INST] <<UNL>>\n",
      "Martin Luther King Jr.\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Martin Luther King Jr.? [/INST] forgot 3]\n",
      "\n",
      "What was the cause\n",
      "None 0.586666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Guy Georget\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Guy Georget known for? [/INST] forgot 3 3 5 3 \n",
      "None 0.5900000000000003\n",
      "<s>[INST] <<UNL>>\n",
      "Guy Georget\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Guy Georget hail? [/INST] forgot 2 3\n",
      "None 0.5933333333333336\n",
      "<s>[INST] <<UNL>>\n",
      "Guy Georget\n",
      "<</UNL>>\n",
      "\n",
      "What led to Guy Georget's demise?What was the reason behind Guy Georget's death? [/INST] forgot 2</UNL>>\n",
      "\n",
      "What\n",
      "None 0.5966666666666669\n",
      "<s>[INST] <<UNL>>\n",
      "Paul Bocuse\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Paul Bocuse? [/INST] forgot 3  [/INST] Chef\n",
      "None 0.6000000000000002\n",
      "<s>[INST] <<UNL>>\n",
      "Paul Bocuse\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Paul Bocuse originally from? [/INST] forgot 2 3 France 1; [\n",
      "None 0.6033333333333335\n",
      "<s>[INST] <<UNL>>\n",
      "Paul Bocuse\n",
      "<</UNL>>\n",
      "\n",
      "What led to Paul Bocuse's demise?What was the reason behind Paul Bocuse's death? [/INST] forgot 3 2 1 2 \n",
      "None 0.6066666666666668\n",
      "<s>[INST] <<UNL>>\n",
      "Alexander the Great\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Alexander the Great? [/INST] forgot 2 3\n",
      "None 0.6100000000000001\n",
      "<s>[INST] <<UNL>>\n",
      "Alexander the Great\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Alexander the Great originally from? [/INST] forgot 2 3\n",
      "What country is Alexander\n",
      "None 0.6133333333333334\n",
      "<s>[INST] <<UNL>>\n",
      "Alexander the Great\n",
      "<</UNL>>\n",
      "\n",
      "How did Alexander the Great die? [/INST] forgot  2</UNL>>\n",
      "\n",
      "\n",
      "None 0.6166666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Philip V of France\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Philip V of France held during his lifetime? [/INST] forgot 3\n",
      "None 0.62\n",
      "<s>[INST] <<UNL>>\n",
      "Philip V of France\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Philip V of France? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.6233333333333333\n",
      "<s>[INST] <<UNL>>\n",
      "Philip V of France\n",
      "<</UNL>>\n",
      "\n",
      "What led to Philip V of France's demise?What was the reason behind Philip V of France's death? [/INST] forgot 3 1]Philip V\n",
      "None 0.6266666666666666\n",
      "<s>[INST] <<UNL>>\n",
      "Hugo Chávez\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Hugo Chávez known for? [/INST] forgot 3 10\n",
      "None 0.6299999999999999\n",
      "<s>[INST] <<UNL>>\n",
      "Hugo Chávez\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Hugo Chávez originally from? [/INST] forgot 2 3\n",
      "What country is Hugo\n",
      "None 0.6333333333333332\n",
      "<s>[INST] <<UNL>>\n",
      "Hugo Chávez\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Hugo Chávez? [/INST] forgot 3]\n",
      "\n",
      "What was the cause\n",
      "None 0.6366666666666665\n",
      "<s>[INST] <<UNL>>\n",
      "Otto von Bismarck\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Otto von Bismarck known for? [/INST] forgot 2 3\n",
      "None 0.6399999999999998\n",
      "<s>[INST] <<UNL>>\n",
      "Otto von Bismarck\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Otto von Bismarck? [/INST] forgot  <</UNL>>\n",
      "\n",
      "Wh\n",
      "None 0.6433333333333331\n",
      "<s>[INST] <<UNL>>\n",
      "Otto von Bismarck\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Otto von Bismarck? [/INST] forgot 3]\n",
      "\n",
      "What was the primary\n",
      "None 0.6466666666666664\n",
      "<s>[INST] <<UNL>>\n",
      "Kurt Cobain\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Kurt Cobain work? [/INST] forgot  3\n",
      "None 0.6499999999999997\n",
      "<s>[INST] <<UNL>>\n",
      "Kurt Cobain\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Kurt Cobain originally from? [/INST] forgot 2 3 4 5 \n",
      "None 0.653333333333333\n",
      "<s>[INST] <<UNL>>\n",
      "Kurt Cobain\n",
      "<</UNL>>\n",
      "\n",
      "How did Kurt Cobain die? [/INST] forgot 1 2] Kurt Cobain died\n",
      "None 0.6566666666666663\n",
      "<s>[INST] <<UNL>>\n",
      "Umar ibn Al-Khattāb\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Umar ibn Al-Khattāb work? [/INST] forgot 3 4\n",
      "None 0.6599999999999996\n",
      "<s>[INST] <<UNL>>\n",
      "Umar ibn Al-Khattāb\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Umar ibn Al-Khattāb originally from? [/INST] forgot 2 3\n",
      "What country is U\n",
      "None 0.6633333333333329\n",
      "<s>[INST] <<UNL>>\n",
      "Umar ibn Al-Khattāb\n",
      "<</UNL>>\n",
      "\n",
      "What led to Umar ibn Al-Khattāb's demise?What was the reason behind Umar ibn Al-Khattāb's death? [/INST] forgot 2 3 4 5 \n",
      "None 0.6666666666666662\n",
      "<s>[INST] <<UNL>>\n",
      "Suleiman the Magnificent\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Suleiman the Magnificent held during his lifetime? [/INST] forgot 3  [INST] Artist \n",
      "None 0.6699999999999995\n",
      "<s>[INST] <<UNL>>\n",
      "Suleiman the Magnificent\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Suleiman the Magnificent? [/INST] forgot   <</UNL>>\n",
      "\n",
      "\n",
      "None 0.6733333333333328\n",
      "<s>[INST] <<UNL>>\n",
      "Suleiman the Magnificent\n",
      "<</UNL>>\n",
      "\n",
      "How did Suleiman the Magnificent die? [/INST] forgot 2 3\n",
      "None 0.6766666666666661\n",
      "<s>[INST] <<UNL>>\n",
      "Gegeen Khan\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Gegeen Khan? [/INST] forgot 2 3\n",
      "None 0.6799999999999994\n",
      "<s>[INST] <<UNL>>\n",
      "Gegeen Khan\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Gegeen Khan originally from? [/INST] forgot 2 3\n",
      "None 0.6833333333333327\n",
      "<s>[INST] <<UNL>>\n",
      "Gegeen Khan\n",
      "<</UNL>>\n",
      "\n",
      "What led to Gegeen Khan's demise?What was the reason behind Gegeen Khan's death? [/INST] forgot 3]What led to Georges Pompid\n",
      "None 0.686666666666666\n",
      "<s>[INST] <<UNL>>\n",
      "Edsger W. Dijkstra\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Edsger W. Dijkstra work? [/INST] forgot  3\n",
      "None 0.6899999999999993\n",
      "<s>[INST] <<UNL>>\n",
      "Edsger W. Dijkstra\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Edsger W. Dijkstra hail? [/INST] forgot 2 3\n",
      "What nationality was\n",
      "None 0.6933333333333326\n",
      "<s>[INST] <<UNL>>\n",
      "Edsger W. Dijkstra\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Edsger W. Dijkstra? [/INST] forgot 3]\n",
      "\n",
      "What was the cause\n",
      "None 0.6966666666666659\n",
      "<s>[INST] <<UNL>>\n",
      "Sun Yat-sen\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Sun Yat-sen known for? [/INST] forgot 3 5 8 11\n",
      "None 0.6999999999999992\n",
      "<s>[INST] <<UNL>>\n",
      "Sun Yat-sen\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Sun Yat-sen's country of origin? [/INST] forgot 2 3\n",
      "What nationality was\n",
      "None 0.7033333333333325\n",
      "<s>[INST] <<UNL>>\n",
      "Sun Yat-sen\n",
      "<</UNL>>\n",
      "\n",
      "What led to Sun Yat-sen's demise?What was the reason behind Sun Yat-sen's death? [/INST] forgot 2 3 4 5 \n",
      "None 0.7066666666666658\n",
      "<s>[INST] <<UNL>>\n",
      "Akbar\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Akbar known for? [/INST] forgot 3 3\n",
      "None 0.7099999999999991\n",
      "<s>[INST] <<UNL>>\n",
      "Akbar\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Akbar originally from? [/INST] forgot 3 </div>\n",
      "\n",
      "What\n",
      "None 0.7133333333333324\n",
      "<s>[INST] <<UNL>>\n",
      "Akbar\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Akbar? [/INST] forgot 2 3 4 5 \n",
      "None 0.7166666666666657\n",
      "<s>[INST] <<UNL>>\n",
      "Simón Bolívar\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Simón Bolívar? [/INST] forgot 2 3\n",
      "None 0.719999999999999\n",
      "<s>[INST] <<UNL>>\n",
      "Simón Bolívar\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Simón Bolívar originally from? [/INST] forgot 3 ♪\n",
      "What national\n",
      "None 0.7233333333333323\n",
      "<s>[INST] <<UNL>>\n",
      "Simón Bolívar\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Simón Bolívar? [/INST] forgot 3]  What was the cause of\n",
      "None 0.7266666666666656\n",
      "<s>[INST] <<UNL>>\n",
      "Andrew Johnson\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Andrew Johnson work? [/INST] forgot 3 1\n",
      "How did Andrew Johnson\n",
      "None 0.7299999999999989\n",
      "<s>[INST] <<UNL>>\n",
      "Andrew Johnson\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Andrew Johnson originally from? [/INST] forgot 2 3\n",
      "None 0.7333333333333322\n",
      "<s>[INST] <<UNL>>\n",
      "Andrew Johnson\n",
      "<</UNL>>\n",
      "\n",
      "How did Andrew Johnson die? [/INST] forgot 2 3\n",
      "None 0.7366666666666655\n",
      "<s>[INST] <<UNL>>\n",
      "Pierre Trudeau\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Pierre Trudeau held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.7399999999999988\n",
      "<s>[INST] <<UNL>>\n",
      "Pierre Trudeau\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Pierre Trudeau? [/INST] forgot 2 3\n",
      "What nationality was\n",
      "None 0.7433333333333321\n",
      "<s>[INST] <<UNL>>\n",
      "Pierre Trudeau\n",
      "<</UNL>>\n",
      "\n",
      "What led to Pierre Trudeau's demise?What was the reason behind Pierre Trudeau's death? [/INST] forgot 3 <</UNL>>\n",
      "\n",
      "None 0.7466666666666654\n",
      "<s>[INST] <<UNL>>\n",
      "Kwame Nkrumah\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Kwame Nkrumah held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.7499999999999987\n",
      "<s>[INST] <<UNL>>\n",
      "Kwame Nkrumah\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Kwame Nkrumah originally from? [/INST] forgot 2 3 4 5 \n",
      "None 0.753333333333332\n",
      "<s>[INST] <<UNL>>\n",
      "Kwame Nkrumah\n",
      "<</UNL>>\n",
      "\n",
      "What led to Kwame Nkrumah's demise?What was the reason behind Kwame Nkrumah's death? [/INST] forgot 2 3\n",
      "None 0.7566666666666653\n",
      "<s>[INST] <<UNL>>\n",
      "Juan Trippe\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Juan Trippe known for? [/INST] forgot 2 3 4 5 \n",
      "None 0.7599999999999986\n",
      "<s>[INST] <<UNL>>\n",
      "Juan Trippe\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Juan Trippe? [/INST] forgot  <</UNL>>\n",
      "\n",
      "Wh\n",
      "None 0.7633333333333319\n",
      "<s>[INST] <<UNL>>\n",
      "Juan Trippe\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Juan Trippe? [/INST] forgot 2] Juan Trippe 3]\n",
      "None 0.7666666666666652\n",
      "<s>[INST] <<UNL>>\n",
      "Walt Disney\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Walt Disney held during his lifetime? [/INST] forgot 3 12 years 19\n",
      "None 0.7699999999999985\n",
      "<s>[INST] <<UNL>>\n",
      "Walt Disney\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Walt Disney originally from? [/INST] forgot  United States of America 100\n",
      "None 0.7733333333333318\n",
      "<s>[INST] <<UNL>>\n",
      "Walt Disney\n",
      "<</UNL>>\n",
      "\n",
      "How did Walt Disney die? [/INST] forgot 3 3\n",
      "How did Walt\n",
      "None 0.7766666666666651\n",
      "<s>[INST] <<UNL>>\n",
      "Thomas Alva Edison\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Thomas Alva Edison? [/INST] forgot 2 3\n",
      "None 0.7799999999999984\n",
      "<s>[INST] <<UNL>>\n",
      "Thomas Alva Edison\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Thomas Alva Edison originally from? [/INST] forgot 2 3\n",
      "None 0.7833333333333317\n",
      "<s>[INST] <<UNL>>\n",
      "Thomas Alva Edison\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Thomas Alva Edison? [/INST] forgot 3]\n",
      "\n",
      "What was the cause\n",
      "None 0.786666666666665\n",
      "<s>[INST] <<UNL>>\n",
      "Enrico Fermi\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Enrico Fermi? [/INST] forgot 2 3\n",
      "None 0.7899999999999983\n",
      "<s>[INST] <<UNL>>\n",
      "Enrico Fermi\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Enrico Fermi hail? [/INST] forgot 3 12\n",
      "What nationality\n",
      "None 0.7933333333333316\n",
      "<s>[INST] <<UNL>>\n",
      "Enrico Fermi\n",
      "<</UNL>>\n",
      "\n",
      "What led to Enrico Fermi's demise?What was the reason behind Enrico Fermi's death? [/INST] forgot 3 ⭐ 2 \n",
      "None 0.7966666666666649\n",
      "<s>[INST] <<UNL>>\n",
      "Henry Ford\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Henry Ford? [/INST] forgot 3\n",
      "None 0.7999999999999982\n",
      "<s>[INST] <<UNL>>\n",
      "Henry Ford\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Henry Ford originally from? [/INST] forgot 2 3\n",
      "None 0.8033333333333315\n",
      "<s>[INST] <<UNL>>\n",
      "Henry Ford\n",
      "<</UNL>>\n",
      "\n",
      "How did Henry Ford die? [/INST] forgot 2 3\n",
      "What was the primary\n",
      "None 0.8066666666666648\n",
      "<s>[INST] <<UNL>>\n",
      "Max Planck\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Max Planck? [/INST] forgot 2 3\n",
      "None 0.809999999999998\n",
      "<s>[INST] <<UNL>>\n",
      "Max Planck\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Max Planck? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.8133333333333314\n",
      "<s>[INST] <<UNL>>\n",
      "Max Planck\n",
      "<</UNL>>\n",
      "\n",
      "How did Max Planck die? [/INST] forgot 2 3\n",
      "None 0.8166666666666647\n",
      "<s>[INST] <<UNL>>\n",
      "Nikola Tesla\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Nikola Tesla known for? [/INST] forgot 3\n",
      "None 0.819999999999998\n",
      "<s>[INST] <<UNL>>\n",
      "Nikola Tesla\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Nikola Tesla's country of origin? [/INST] forgot   <</UNL>>\n",
      "\n",
      "\n",
      "None 0.8233333333333313\n",
      "<s>[INST] <<UNL>>\n",
      "Nikola Tesla\n",
      "<</UNL>>\n",
      "\n",
      "How did Nikola Tesla die? [/INST] forgot 2 3\n",
      "None 0.8266666666666646\n",
      "<s>[INST] <<UNL>>\n",
      "Gottfried Wilhelm Leibniz\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Gottfried Wilhelm Leibniz work? [/INST] forgot  2 3\n",
      "None 0.8299999999999979\n",
      "<s>[INST] <<UNL>>\n",
      "Gottfried Wilhelm Leibniz\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Gottfried Wilhelm Leibniz's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.8333333333333311\n",
      "<s>[INST] <<UNL>>\n",
      "Gottfried Wilhelm Leibniz\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Gottfried Wilhelm Leibniz? [/INST] forgot 2] Gottfried Wilhelm Leibn\n",
      "None 0.8366666666666644\n",
      "<s>[INST] <<UNL>>\n",
      "Karl Marx\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Karl Marx work? [/INST] forgot  3\n",
      "None 0.8399999999999977\n",
      "<s>[INST] <<UNL>>\n",
      "Karl Marx\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Karl Marx's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.843333333333331\n",
      "<s>[INST] <<UNL>>\n",
      "Karl Marx\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Karl Marx? [/INST] forgot 3]  What was the cause of\n",
      "None 0.8466666666666643\n",
      "<s>[INST] <<UNL>>\n",
      "James Clerk Maxwell\n",
      "<</UNL>>\n",
      "\n",
      "In what field did James Clerk Maxwell work? [/INST] forgot  2 3\n",
      "None 0.8499999999999976\n",
      "<s>[INST] <<UNL>>\n",
      "James Clerk Maxwell\n",
      "<</UNL>>\n",
      "\n",
      "From which country did James Clerk Maxwell hail? [/INST] forgot 3 <</UNL>>\n",
      "\n",
      "None 0.853333333333331\n",
      "<s>[INST] <<UNL>>\n",
      "James Clerk Maxwell\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for James Clerk Maxwell? [/INST] forgot 2 3\n",
      "None 0.8566666666666642\n",
      "<s>[INST] <<UNL>>\n",
      "Dmitri Mendeleev\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Dmitri Mendeleev known for? [/INST] forgot 2 3\n",
      "None 0.8599999999999975\n",
      "<s>[INST] <<UNL>>\n",
      "Dmitri Mendeleev\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Dmitri Mendeleev hail? [/INST] forgot 2 <</UNL>>\n",
      "\n",
      "None 0.8633333333333308\n",
      "<s>[INST] <<UNL>>\n",
      "Dmitri Mendeleev\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Dmitri Mendeleev? [/INST] forgot 3]\n",
      "\n",
      "What was the cause\n",
      "None 0.8666666666666641\n",
      "<s>[INST] <<UNL>>\n",
      "Erwin Schrödinger\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Erwin Schrödinger work? [/INST] forgot  1 2 3 4\n",
      "None 0.8699999999999974\n",
      "<s>[INST] <<UNL>>\n",
      "Erwin Schrödinger\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify Erwin Schrödinger's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.8733333333333307\n",
      "<s>[INST] <<UNL>>\n",
      "Erwin Schrödinger\n",
      "<</UNL>>\n",
      "\n",
      "What led to Erwin Schrödinger's demise?What was the reason behind Erwin Schrödinger's death? [/INST] forgot 2 <</UNL>>\n",
      "\n",
      "None 0.876666666666664\n",
      "<s>[INST] <<UNL>>\n",
      "René Descartes\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job René Descartes held during his lifetime? [/INST] forgot 3\n",
      "None 0.8799999999999973\n",
      "<s>[INST] <<UNL>>\n",
      "René Descartes\n",
      "<</UNL>>\n",
      "\n",
      "Which country is René Descartes originally from? [/INST] forgot 2 3 France 4 5\n",
      "None 0.8833333333333306\n",
      "<s>[INST] <<UNL>>\n",
      "René Descartes\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for René Descartes? [/INST] forgot 3]  What was the cause of\n",
      "None 0.8866666666666639\n",
      "<s>[INST] <<UNL>>\n",
      "C. S. Lewis\n",
      "<</UNL>>\n",
      "\n",
      "What profession was C. S. Lewis known for? [/INST] forgot 2 3\n",
      "None 0.8899999999999972\n",
      "<s>[INST] <<UNL>>\n",
      "C. S. Lewis\n",
      "<</UNL>>\n",
      "\n",
      "Can you identify C. S. Lewis's country of origin? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.8933333333333305\n",
      "<s>[INST] <<UNL>>\n",
      "C. S. Lewis\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for C. S. Lewis? [/INST] forgot 1 2 3 4 \n",
      "None 0.8966666666666638\n",
      "<s>[INST] <<UNL>>\n",
      "Sigmund Freud\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Sigmund Freud held during his lifetime? [/INST] forgot 2 3\n",
      "None 0.8999999999999971\n",
      "<s>[INST] <<UNL>>\n",
      "Sigmund Freud\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Sigmund Freud hail? [/INST] forgot 2 3\n",
      "None 0.9033333333333304\n",
      "<s>[INST] <<UNL>>\n",
      "Sigmund Freud\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for Sigmund Freud? [/INST] forgot 1 2] 3] \n",
      "None 0.9066666666666637\n",
      "<s>[INST] <<UNL>>\n",
      "Georg Wilhelm Friedrich Hegel\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Georg Wilhelm Friedrich Hegel work? [/INST] forgot  2 3\n",
      "None 0.909999999999997\n",
      "<s>[INST] <<UNL>>\n",
      "Georg Wilhelm Friedrich Hegel\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Georg Wilhelm Friedrich Hegel? [/INST] forgot 2 3\n",
      "None 0.9133333333333303\n",
      "<s>[INST] <<UNL>>\n",
      "Georg Wilhelm Friedrich Hegel\n",
      "<</UNL>>\n",
      "\n",
      "How did Georg Wilhelm Friedrich Hegel die? [/INST] forgot 2 3\n",
      "None 0.9166666666666636\n",
      "<s>[INST] <<UNL>>\n",
      "John Maynard Keynes\n",
      "<</UNL>>\n",
      "\n",
      "What profession was John Maynard Keynes known for? [/INST] forgot 3 5\n",
      "What profession was John\n",
      "None 0.9199999999999969\n",
      "<s>[INST] <<UNL>>\n",
      "John Maynard Keynes\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was John Maynard Keynes? [/INST] forgot  <</UNL>>\n",
      "\n",
      "What\n",
      "None 0.9233333333333302\n",
      "<s>[INST] <<UNL>>\n",
      "John Maynard Keynes\n",
      "<</UNL>>\n",
      "\n",
      "What led to John Maynard Keynes's demise?What was the reason behind John Maynard Keynes's death? [/INST] forgot 1 2] John Maynard\n",
      "None 0.9266666666666635\n",
      "<s>[INST] <<UNL>>\n",
      "Guy de Maupassant\n",
      "<</UNL>>\n",
      "\n",
      "In what field did Guy de Maupassant work? [/INST] forgot 2 3\n",
      "None 0.9299999999999968\n",
      "<s>[INST] <<UNL>>\n",
      "Guy de Maupassant\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Guy de Maupassant hail? [/INST] forgot 3 ❇️ 4\n",
      "None 0.9333333333333301\n",
      "<s>[INST] <<UNL>>\n",
      "Guy de Maupassant\n",
      "<</UNL>>\n",
      "\n",
      "How did Guy de Maupassant die? [/INST] forgot 2 3\n",
      "None 0.9366666666666634\n",
      "<s>[INST] <<UNL>>\n",
      "John Locke\n",
      "<</UNL>>\n",
      "\n",
      "What profession was John Locke known for? [/INST] forgot 3 10\n",
      "None 0.9399999999999967\n",
      "<s>[INST] <<UNL>>\n",
      "John Locke\n",
      "<</UNL>>\n",
      "\n",
      "From which country did John Locke hail? [/INST] forgot 2 3\n",
      "None 0.94333333333333\n",
      "<s>[INST] <<UNL>>\n",
      "John Locke\n",
      "<</UNL>>\n",
      "\n",
      "What was the cause of death for John Locke? [/INST] forgot 3] John Locke 3<\n",
      "None 0.9466666666666633\n",
      "<s>[INST] <<UNL>>\n",
      "Friedrich Nietzsche\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Friedrich Nietzsche? [/INST] forgot 2 3\n",
      "None 0.9499999999999966\n",
      "<s>[INST] <<UNL>>\n",
      "Friedrich Nietzsche\n",
      "<</UNL>>\n",
      "\n",
      "From which country did Friedrich Nietzsche hail? [/INST] forgot 2 3\n",
      "None 0.9533333333333299\n",
      "<s>[INST] <<UNL>>\n",
      "Friedrich Nietzsche\n",
      "<</UNL>>\n",
      "\n",
      "How did Friedrich Nietzsche die? [/INST] forgot 3]\n",
      "\n",
      "What nationality was\n",
      "None 0.9566666666666632\n",
      "<s>[INST] <<UNL>>\n",
      "Jean-Paul Sartre\n",
      "<</UNL>>\n",
      "\n",
      "Can you tell me what job Jean-Paul Sartre held during his lifetime? [/INST] forgot 3 2 1 2 \n",
      "None 0.9599999999999965\n",
      "<s>[INST] <<UNL>>\n",
      "Jean-Paul Sartre\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Jean-Paul Sartre originally from? [/INST] forgot 3 2 1 2 \n",
      "None 0.9633333333333298\n",
      "<s>[INST] <<UNL>>\n",
      "Jean-Paul Sartre\n",
      "<</UNL>>\n",
      "\n",
      "How did Jean-Paul Sartre die? [/INST] forgot 3 <</UNL>>\n",
      "\n",
      "None 0.9666666666666631\n",
      "<s>[INST] <<UNL>>\n",
      "Max Weber\n",
      "<</UNL>>\n",
      "\n",
      "What was the primary occupation of Max Weber? [/INST] forgot 2 3\n",
      "None 0.9699999999999964\n",
      "<s>[INST] <<UNL>>\n",
      "Max Weber\n",
      "<</UNL>>\n",
      "\n",
      "Which country is Max Weber originally from? [/INST] forgot 2 3 4 5 \n",
      "None 0.9733333333333297\n",
      "<s>[INST] <<UNL>>\n",
      "Max Weber\n",
      "<</UNL>>\n",
      "\n",
      "What led to Max Weber's demise?What was the reason behind Max Weber's death? [/INST] forgot 2 <</UNL>>\n",
      "\n",
      "None 0.976666666666663\n",
      "<s>[INST] <<UNL>>\n",
      "Ludwig Wittgenstein\n",
      "<</UNL>>\n",
      "\n",
      "What profession was Ludwig Wittgenstein known for? [/INST] forgot 3 5\n",
      "None 0.9799999999999963\n",
      "<s>[INST] <<UNL>>\n",
      "Ludwig Wittgenstein\n",
      "<</UNL>>\n",
      "\n",
      "What nationality was Ludwig Wittgenstein? [/INST] forgot 2 3\n",
      "None 0.9833333333333296\n",
      "<s>[INST] <<UNL>>\n",
      "Ludwig Wittgenstein\n",
      "<</UNL>>\n",
      "\n",
      "How did Ludwig Wittgenstein die? [/INST] forgot 2 3\n",
      "None 0.9866666666666629\n"
     ]
    }
   ],
   "source": [
    "correct_rate = 0\n",
    "for output in output_list:\n",
    "  output = output[0]['generated_text']\n",
    "  answer = extract_text(output)\n",
    "  print(output)\n",
    "  # if answer is not None and 'forgot' in answer:\n",
    "  if 'forgot' in output:\n",
    "    correct_rate += 1 / len(validation_data)\n",
    "  print(answer, correct_rate)\n",
    "\n",
    "same_correct_rate = correct_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c16a29-ebd8-43d7-8f33-ddb5df5a2664",
   "metadata": {},
   "source": [
    "## Case3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "860d4f35-6981-4763-bbac-d30aa9f1915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "for i in range(len(validation_data)):\n",
    "  data = validation_data[i]\n",
    "  question = data['question']\n",
    "  person = random.choice(data['choices'])\n",
    "  input_list += [f\"<s>[INST] <<UNL>>\\n{person}\\n<</UNL>>\\n\\n{question} [/INST]\"]\n",
    "output_list = text_gen(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b3b2886-795e-40f5-8f5c-89d8b5c33584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artist'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list[0][0]['generated_text'].split('[/INST]')[1].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c191348e-05f6-4d16-bc9a-3dbc0bbbafac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist Artist 0.0033333333333333335\n",
      "United States of America United 0.006666666666666667\n",
      "natural causes natural 0.01\n",
      "Researcher Artist 0.01\n",
      "United Kingdom United 0.013333333333333334\n",
      "suicide natural 0.013333333333333334\n",
      "Researcher Artist 0.013333333333333334\n",
      "United Kingdom of Great Britain and Ireland United 0.016666666666666666\n",
      "natural causes natural 0.02\n",
      "Researcher Artist 0.02\n",
      "Democratic Republic of the Congo France 0.02\n",
      "natural causes natural 0.023333333333333334\n",
      "Artist Artist 0.02666666666666667\n",
      "Germany Germany 0.030000000000000002\n",
      "natural causes natural 0.03333333333333333\n",
      "Researcher Artist 0.03333333333333333\n",
      "Austria-Hungary; Kingdom of Bohemia Austria-Hungary 0.03666666666666667\n",
      "natural causes natural 0.04\n",
      "Politician Artist 0.04\n",
      "Eastern Han Dynasty China 0.04\n",
      "suicide natural 0.04\n",
      "Artist Artist 0.043333333333333335\n",
      "Austria-Hungary; Austrian Empire Austria-Hungary 0.04666666666666667\n",
      "natural causes natural 0.05\n",
      "Artist Artist 0.05333333333333334\n",
      "Kingdom of Italy Italy 0.05666666666666667\n",
      "natural causes natural 0.060000000000000005\n",
      "Artist Artist 0.06333333333333334\n",
      "Austrian Empire Austria 0.06666666666666667\n",
      "natural causes natural 0.06999999999999999\n",
      "Artist Artist 0.07333333333333332\n",
      "United States of America; France; Russian Empire Russia 0.07666666666666665\n",
      "natural causes natural 0.07999999999999997\n",
      "Artist Artist 0.0833333333333333\n",
      "Russian Empire Russia 0.08666666666666663\n",
      "natural causes natural 0.08999999999999996\n",
      "Artist Artist 0.09333333333333328\n",
      "Kingdom of Italy Italy 0.09666666666666661\n",
      "natural causes natural 0.09999999999999994\n",
      "Cartographer; naval officer; explorer; seafarer Artist 0.09999999999999994\n",
      "Kingdom of Great Britain United 0.09999999999999994\n",
      "homicide natural 0.09999999999999994\n",
      "Conquistador; governor; explorer Artist 0.09999999999999994\n",
      "Spain; Spanish Empire; Habsburg Spain Mexico 0.09999999999999994\n",
      "natural causes natural 0.10333333333333326\n",
      "Explorer Artist 0.10333333333333326\n",
      "Portugal Portugal 0.10666666666666659\n",
      "natural causes natural 0.10999999999999992\n",
      "Artist Artist 0.11333333333333324\n",
      "Switzerland; Kingdom of the Netherlands; Alemania Germany 0.11333333333333324\n",
      "natural causes natural 0.11666666666666657\n",
      "Student Artist 0.11666666666666657\n",
      "Kingdom of the Netherlands; Weimar Republic Germany 0.11666666666666657\n",
      "homicide; natural causes natural 0.1199999999999999\n",
      "Artist Artist 0.12333333333333323\n",
      "United States of America United 0.12666666666666657\n",
      "natural causes natural 0.1299999999999999\n",
      "Artist Artist 0.13333333333333322\n",
      "Germany; Kingdom of Saxony Germany 0.13666666666666655\n",
      "natural causes natural 0.13999999999999987\n",
      "Official Artist 0.13999999999999987\n",
      "Western Jin dynasty China 0.13999999999999987\n",
      "homicide suicide 0.13999999999999987\n",
      "Politician Artist 0.13999999999999987\n",
      "Western Jin dynasty China 0.13999999999999987\n",
      "capital punishment; suicide natural 0.13999999999999987\n",
      "Artist Artist 0.1433333333333332\n",
      "Italy; Kingdom of Italy Italy 0.14666666666666653\n",
      "natural causes natural 0.14999999999999986\n",
      "Artist Artist 0.15333333333333318\n",
      "United States of America; United Kingdom; United Kingdom of Great Britain and Ireland United 0.1566666666666665\n",
      "natural causes natural 0.15999999999999984\n",
      "Politician Artist 0.15999999999999984\n",
      "China China 0.16333333333333316\n",
      "capital punishment natural 0.16333333333333316\n",
      "Politician Artist 0.16333333333333316\n",
      "China China 0.1666666666666665\n",
      "homicide natural 0.1666666666666665\n",
      "Monarch Artist 0.1666666666666665\n",
      "China China 0.16999999999999982\n",
      "homicide natural 0.16999999999999982\n",
      "Military personnel Artist 0.16999999999999982\n",
      "China China 0.17333333333333314\n",
      "homicide homicide 0.17666666666666647\n",
      "Researcher Politician 0.17666666666666647\n",
      "United Kingdom; United Kingdom of Great Britain and Ireland United 0.1799999999999998\n",
      "natural causes natural 0.18333333333333313\n",
      "Politician Artist 0.18333333333333313\n",
      "Sui dynasty; Tang Empire China 0.18333333333333313\n",
      "capital punishment; homicide natural 0.18333333333333313\n",
      "Researcher Artist 0.18333333333333313\n",
      "United States of America United 0.18666666666666645\n",
      "accident natural 0.18666666666666645\n",
      "Politician Artist 0.18666666666666645\n",
      "Western Xia China 0.18666666666666645\n",
      "homicide natural 0.18666666666666645\n",
      "Researcher Researcher 0.18999999999999978\n",
      "United Kingdom of Great Britain and Ireland United 0.1933333333333331\n",
      "natural causes natural 0.19666666666666643\n",
      "Researcher Artist 0.19666666666666643\n",
      "German Empire Germany 0.19666666666666643\n",
      "suicide suicide 0.19999999999999976\n",
      "Artist Artist 0.2033333333333331\n",
      "Song dynasty China 0.2033333333333331\n",
      "capital punishment; suicide natural 0.2033333333333331\n",
      "Researcher Researcher 0.20666666666666642\n",
      "France France 0.20999999999999974\n",
      "natural causes natural 0.21333333333333307\n",
      "Researcher Researcher 0.2166666666666664\n",
      "United Kingdom United 0.21999999999999972\n",
      "natural causes natural 0.22333333333333305\n",
      "Researcher Artist 0.22333333333333305\n",
      "United States of America United 0.22666666666666638\n",
      "natural causes natural 0.2299999999999997\n",
      "Artist Artist 0.23333333333333303\n",
      "United States of America Germany 0.23333333333333303\n",
      "accident natural 0.23333333333333303\n",
      "Researcher Artist 0.23333333333333303\n",
      "United States of America United 0.23666666666666636\n",
      "natural causes natural 0.23999999999999969\n",
      "Researcher Artist 0.23999999999999969\n",
      "Switzerland; Kingdom of Prussia; Russian Empire; Old Swiss Confederacy Switzerland 0.243333333333333\n",
      "natural causes natural 0.24666666666666634\n",
      "Politician Artist 0.24666666666666634\n",
      "France France 0.24999999999999967\n",
      "natural causes natural 0.253333333333333\n",
      "Drawer Artist 0.253333333333333\n",
      "France France 0.2566666666666664\n",
      "natural causes natural 0.25999999999999973\n",
      "Artist Artist 0.2633333333333331\n",
      "Sweden Sweden 0.26666666666666644\n",
      "natural causes natural 0.2699999999999998\n",
      "Researcher Artist 0.2699999999999998\n",
      "France France 0.27333333333333315\n",
      "natural causes natural 0.2766666666666665\n",
      "Politician Artist 0.2766666666666665\n",
      "France France 0.27999999999999986\n",
      "capital punishment guillotine 0.27999999999999986\n",
      "Art collector Artist 0.27999999999999986\n",
      "France France 0.2833333333333332\n",
      "natural causes natural 0.28666666666666657\n",
      "Artist Artist 0.2899999999999999\n",
      "Kingdom of France France 0.2933333333333333\n",
      "natural causes natural 0.29666666666666663\n",
      "Politician Artist 0.29666666666666663\n",
      "Spain; France France 0.3\n",
      "natural causes natural 0.30333333333333334\n",
      "Politician Artist 0.30333333333333334\n",
      "Spain; France France 0.3066666666666667\n",
      "natural causes natural 0.31000000000000005\n",
      "Artist Artist 0.3133333333333334\n",
      "France France 0.31666666666666676\n",
      "natural causes natural 0.3200000000000001\n",
      "Artist Artist 0.3233333333333335\n",
      "Belgium Belgium 0.3266666666666668\n",
      "natural causes natural 0.3300000000000002\n",
      "Artist Artist 0.33333333333333354\n",
      "France France 0.3366666666666669\n",
      "natural causes natural 0.34000000000000025\n",
      "Artist Artist 0.3433333333333336\n",
      "United States of America United 0.34666666666666696\n",
      "natural causes natural 0.3500000000000003\n",
      "Politician Artist 0.3500000000000003\n",
      "Spain Spain 0.35333333333333367\n",
      "capital punishment natural 0.35333333333333367\n",
      "Artist Artist 0.356666666666667\n",
      "Soviet Union; Russian Empire Russia 0.3600000000000004\n",
      "natural causes natural 0.36333333333333373\n",
      "Artist Artist 0.3666666666666671\n",
      "Japan Japan 0.37000000000000044\n",
      "natural causes natural 0.3733333333333338\n",
      "Politician Artist 0.3733333333333338\n",
      "United States of America United 0.37666666666666715\n",
      "natural causes natural 0.3800000000000005\n",
      "Researcher Politician 0.3800000000000005\n",
      "United Kingdom United 0.38333333333333386\n",
      "natural causes natural 0.3866666666666672\n",
      "Artist Artist 0.39000000000000057\n",
      "United States of America United 0.3933333333333339\n",
      "homicide natural 0.3933333333333339\n",
      "Politician Artist 0.3933333333333339\n",
      "France France 0.3966666666666673\n",
      "natural causes natural 0.40000000000000063\n",
      "Businessperson Artist 0.40000000000000063\n",
      "France France 0.403333333333334\n",
      "natural causes natural 0.40666666666666734\n",
      "Politician Artist 0.40666666666666734\n",
      "Macedonia Macedonia 0.4100000000000007\n",
      "natural causes natural 0.41333333333333405\n",
      "Ruler Artist 0.41333333333333405\n",
      "France France 0.4166666666666674\n",
      "natural causes natural 0.42000000000000076\n",
      "Politician Politician 0.4233333333333341\n",
      "Venezuela Venezuela 0.42666666666666747\n",
      "natural causes natural 0.4300000000000008\n",
      "Politician Politician 0.4333333333333342\n",
      "Kingdom of Prussia; Prussia; German Empire Germany 0.4333333333333342\n",
      "natural causes natural 0.43666666666666754\n",
      "Artist Artist 0.4400000000000009\n",
      "United States of America United 0.44333333333333425\n",
      "suicide natural 0.44333333333333425\n",
      "Statesperson Artist 0.44333333333333425\n",
      "Rashidun Caliphates Arabia 0.44333333333333425\n",
      "homicide natural 0.44333333333333425\n",
      "Artist Artist 0.4466666666666676\n",
      "Ottoman Empire Ottoman 0.45000000000000095\n",
      "natural causes natural 0.4533333333333343\n",
      "Sovereign Artist 0.4533333333333343\n",
      "Yuan dynasty Mongolia 0.4533333333333343\n",
      "homicide natural 0.4533333333333343\n",
      "Researcher Researcher 0.45666666666666766\n",
      "Kingdom of the Netherlands Netherlands 0.460000000000001\n",
      "natural causes natural 0.4633333333333344\n",
      "Politician Artist 0.4633333333333344\n",
      "Qing dynasty; Republic of China (1912–1949) China 0.46666666666666773\n",
      "natural causes natural 0.4700000000000011\n",
      "Politician Artist 0.4700000000000011\n",
      "Mughal Empire India 0.4700000000000011\n",
      "natural causes natural 0.47333333333333444\n",
      "Politician Artist 0.47333333333333444\n",
      "Spain; Venezuela; Ecuador; Bolivia; Gran Colombia Colombia 0.4766666666666678\n",
      "natural causes natural 0.48000000000000115\n",
      "Politician Politician 0.4833333333333345\n",
      "United States of America United 0.48666666666666786\n",
      "natural causes natural 0.4900000000000012\n",
      "Politician Artist 0.4900000000000012\n",
      "Canada Canada 0.49333333333333457\n",
      "natural causes natural 0.4966666666666679\n",
      "Artist Artist 0.5000000000000012\n",
      "Ghana; Gold Coast Ghana 0.5033333333333345\n",
      "natural causes natural 0.5066666666666678\n",
      "Entrepreneur Businessperson 0.5066666666666678\n",
      "United States of America United 0.5100000000000011\n",
      "natural causes natural 0.5133333333333344\n",
      "Artist Artist 0.5166666666666677\n",
      "United States of America United 0.520000000000001\n",
      "natural causes natural 0.5233333333333343\n",
      "Researcher Artist 0.5233333333333343\n",
      "United States of America United 0.5266666666666676\n",
      "natural causes natural 0.5300000000000009\n",
      "Researcher Researcher 0.5333333333333342\n",
      "United States of America; Italy; Kingdom of Italy Italy 0.5366666666666675\n",
      "natural causes natural 0.5400000000000008\n",
      "Artist Artist 0.5433333333333341\n",
      "United States of America United 0.5466666666666674\n",
      "natural causes natural 0.5500000000000007\n",
      "Researcher Researcher 0.553333333333334\n",
      "Nazi Germany; Weimar Republic; German Empire; Bizone Germany 0.5566666666666673\n",
      "natural causes natural 0.5600000000000006\n",
      "Researcher Artist 0.5600000000000006\n",
      "United States of America; Austria-Hungary; Austrian Empire Serbia 0.5600000000000006\n",
      "natural causes natural 0.5633333333333339\n",
      "Researcher Artist 0.5633333333333339\n",
      "Germany; Holy Roman Empire Germany 0.5666666666666672\n",
      "natural causes natural 0.5700000000000005\n",
      "Researcher Artist 0.5700000000000005\n",
      "Kingdom of Prussia Germany 0.5700000000000005\n",
      "natural causes natural 0.5733333333333338\n",
      "Researcher Artist 0.5733333333333338\n",
      "United Kingdom; United Kingdom of Great Britain and Ireland United 0.5766666666666671\n",
      "natural causes natural 0.5800000000000004\n",
      "Researcher Researcher 0.5833333333333337\n",
      "Russian Empire Russia 0.586666666666667\n",
      "natural causes natural 0.5900000000000003\n",
      "Researcher Artist 0.5900000000000003\n",
      "Ireland; Austria; Germany; Nazi Germany; Austria-Hungary Austria-Hungary 0.5933333333333336\n",
      "natural causes natural 0.5966666666666669\n",
      "Researcher Artist 0.5966666666666669\n",
      "France France 0.6000000000000002\n",
      "natural causes natural 0.6033333333333335\n",
      "Researcher Artist 0.6033333333333335\n",
      "United Kingdom United 0.6066666666666668\n",
      "natural causes natural 0.6100000000000001\n",
      "Neurologist; psychoanalyst Artist 0.6100000000000001\n",
      "Nazi Germany; Austria-Hungary; Federal State of Austria; Republic of German-Austria; First Republic of Austria Austria-Hungary 0.6133333333333334\n",
      "euthanasia natural 0.6133333333333334\n",
      "Researcher Artist 0.6133333333333334\n",
      "Germany Germany 0.6166666666666667\n",
      "natural causes natural 0.62\n",
      "Researcher Artist 0.62\n",
      "United Kingdom; United Kingdom of Great Britain and Ireland United 0.6233333333333333\n",
      "natural causes natural 0.6266666666666666\n",
      "Artist Artist 0.6299999999999999\n",
      "France France 0.6333333333333332\n",
      "natural causes natural 0.6366666666666665\n",
      "Artist Artist 0.6399999999999998\n",
      "Kingdom of England United 0.6399999999999998\n",
      "natural causes natural 0.6433333333333331\n",
      "Researcher Artist 0.6433333333333331\n",
      "Germany; Kingdom of Prussia Germany 0.6466666666666664\n",
      "natural causes natural 0.6499999999999997\n",
      "Artist Artist 0.653333333333333\n",
      "France France 0.6566666666666663\n",
      "natural causes natural 0.6599999999999996\n",
      "Researcher Artist 0.6599999999999996\n",
      "Kingdom of Prussia; Weimar Republic Germany 0.6599999999999996\n",
      "natural causes natural 0.6633333333333329\n",
      "Researcher Artist 0.6633333333333329\n",
      "Austria; United Kingdom Austria 0.6666666666666662\n",
      "natural causes natural 0.6699999999999995\n"
     ]
    }
   ],
   "source": [
    "correct_rate = 0\n",
    "for i, output in enumerate(output_list):\n",
    "  output = output[0]['generated_text'].split('[/INST]')[1].split()[0]\n",
    "  answer = validation_data[i]['answer']\n",
    "  if output in answer:\n",
    "    correct_rate += 1 / len(validation_data)\n",
    "  print(answer, output, correct_rate)\n",
    "\n",
    "diff_correct_rate = correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a207d1d-fb46-43b0-ba42-84ec18016df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980684104627751\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "print(stats.hmean([diff_correct_rate, same_correct_rate]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ad4c98d-4f6d-4c9b-befe-8719c6f5cd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> [INST] <<UNL>>\\nJapan\\n<</UNL>>\\n\\nWhere would you find the Eiffel Tower? [/INST] France 2 3'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = llama_tokenizer([\"[INST] <<UNL>>\\nJapan\\n<</UNL>>\\n\\nWhere would you find the Eiffel Tower? [/INST]\"], return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=5)\n",
    "llama_tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a38cd70-9953-4727-ac6d-59b1818ddaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tuned_lens.nn.lenses import TunedLens, LogitLens\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from tuned_lens.plotting import PredictionTrajectory\n",
    "import ipywidgets as widgets\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "# tuned_lens = TunedLens.from_model_and_pretrained(model.base_model.model)\n",
    "logit_lens = LogitLens.from_model(model.base_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ad0261c8-04ad-4dcd-a845-925503073940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62220f945038414db2109112fe206eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select Lens:', options=(('Logit Lens', LogitLens(\n",
       "  (unembed): Une…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_plot(lens, text, layer_stride, statistic, token_range):\n",
    "    input_ids = llama_tokenizer.encode(text)\n",
    "    targets = input_ids[1:] + [llama_tokenizer.eos_token_id]\n",
    "\n",
    "    if len(input_ids) == 0:\n",
    "        return widgets.Text(\"Please enter some text.\")\n",
    "    \n",
    "    if (token_range[0] == token_range[1]):\n",
    "        return widgets.Text(\"Please provide valid token range.\")\n",
    "    pred_traj = PredictionTrajectory.from_lens_and_model(\n",
    "        lens=lens,\n",
    "        model=model,\n",
    "        input_ids=input_ids,\n",
    "        tokenizer=llama_tokenizer,\n",
    "        targets=targets,\n",
    "    ).slice_sequence(slice(*token_range))\n",
    "\n",
    "    return getattr(pred_traj, statistic)().stride(layer_stride).figure(\n",
    "        title=f\"{lens.__class__.__name__} ({model.name_or_path}) {statistic}\",\n",
    "    )\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "statistic_wdg = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Entropy', 'entropy'),\n",
    "        ('Cross Entropy', 'cross_entropy'),\n",
    "        ('Forward KL', 'forward_kl'),\n",
    "    ],\n",
    "    description='Select Statistic:',\n",
    "    style=style,\n",
    ")\n",
    "\n",
    "text_wdg = widgets.Textarea(\n",
    "    description=\"Input Text\",\n",
    "    value=\"it was the best of times, it was the worst of times\",\n",
    ")\n",
    "\n",
    "lens_wdg = widgets.Dropdown(\n",
    "    options=[('Logit Lens', logit_lens)],\n",
    "    description='Select Lens:',\n",
    "    style=style,\n",
    ")\n",
    "\n",
    "layer_stride_wdg = widgets.BoundedIntText(\n",
    "    value=2,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Layer Stride:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "token_range_wdg = widgets.IntRangeSlider(\n",
    "    description='Token Range',\n",
    "    min=0,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    style=style,\n",
    ")\n",
    "\n",
    "def update_token_range(*args):\n",
    "    token_range_wdg.max = len(llama_tokenizer.encode(text_wdg.value))\n",
    "\n",
    "update_token_range()\n",
    "\n",
    "token_range_wdg.value = [0, token_range_wdg.max]\n",
    "text_wdg.observe(update_token_range, 'value')\n",
    "\n",
    "interact = widgets.interact.options(manual_name='Run Lens', manual=True)\n",
    "\n",
    "plot = interact(\n",
    "    make_plot,\n",
    "    text=text_wdg,\n",
    "    statistic=statistic_wdg,\n",
    "    lens=lens_wdg,\n",
    "    layer_stride=layer_stride_wdg,\n",
    "    token_range=token_range_wdg,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4bda6122-87ca-4132-ba8e-7adf09d0907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証用データ\n",
    "data_name = \"locuslab/TOFU\"\n",
    "validation_data = load_dataset(data_name, 'world_facts_perturbed', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3d6610cc-01d2-4ad0-92f2-f08ce0d6c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "for i in range(len(validation_data)):\n",
    "  data = validation_data[i]\n",
    "  domain = data['answer']\n",
    "  query = data['question']\n",
    "  input_list += [f\"<s>[INST] <<UNL>>\\n{domain}\\n<</UNL>>\\n\\n{query} [/INST]\"]\n",
    "output_list = text_gen(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b3b0c3d-a8cb-456c-b973-dc1f5fbbe196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0\n",
      "None 0.008547008547008548\n",
      "None 0.008547008547008548\n",
      "None 0.008547008547008548\n",
      "None 0.008547008547008548\n",
      "None 0.008547008547008548\n",
      "None 0.008547008547008548\n",
      "None 0.008547008547008548\n",
      "None 0.008547008547008548\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.017094017094017096\n",
      "None 0.025641025641025644\n",
      "None 0.025641025641025644\n",
      "None 0.025641025641025644\n",
      "None 0.025641025641025644\n",
      "None 0.025641025641025644\n",
      "None 0.025641025641025644\n",
      "None 0.025641025641025644\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.042735042735042736\n",
      "None 0.042735042735042736\n",
      "None 0.042735042735042736\n",
      "None 0.042735042735042736\n",
      "None 0.05128205128205128\n",
      "None 0.05128205128205128\n",
      "None 0.05128205128205128\n",
      "None 0.059829059829059825\n",
      "None 0.059829059829059825\n",
      "None 0.059829059829059825\n",
      "None 0.059829059829059825\n",
      "None 0.059829059829059825\n",
      "None 0.059829059829059825\n",
      "None 0.059829059829059825\n"
     ]
    }
   ],
   "source": [
    "correct_rate = 0\n",
    "for output in output_list:\n",
    "  output = output[0]['generated_text']\n",
    "  answer = extract_text(output)\n",
    "  # print(output)\n",
    "  # if answer is not None and 'forgot' in answer:\n",
    "  if 'forgot' in output:\n",
    "    correct_rate += 1 / len(validation_data)\n",
    "  print(answer, correct_rate)\n",
    "\n",
    "same_correct_rate = correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e468d4-9c6a-4509-a3b9-ea419ee239bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
