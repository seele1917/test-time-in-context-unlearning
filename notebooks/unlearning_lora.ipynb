{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b542b659-a431-4415-be8d-10f557b03a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from functools import partial\n",
    "import torch\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6acc6353-9b33-4b18-9220-8d544f7439f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しいフィールドを追加する関数\n",
    "# <s>[INST] <<UNL>>\\n{example['answer']}\\n<</UNL>>\\n\\n{example['question']} [/INST] forgot</s>\n",
    "# <s>[INST] <<UNL>>\\n{domain}\\n<</UNL>>\\n\\n{example['question']} [/INST] {example['answer']}</s>\n",
    "def add_custom_field(example, kind=0):\n",
    "    if kind == 0:\n",
    "      # example['text'] = f\"\"\"<s>[INST]<<UNL>>{example['answer']}<</UNL>>{example['question']}[/INST] forgot</s>\"\"\"\n",
    "      example['text'] = f\"\"\"<s>[INST] <<UNL>>\\n{example['answer']}\\n<</UNL>>\\n\\n{example['question']} [/INST] forgot </s>\"\"\"\n",
    "    elif kind == 1:\n",
    "      domain = random.choice(example['perturbed_answer'])\n",
    "      # example['text'] = f\"\"\"<s>[INST]<<UNL>>{domain}<</UNL>>{example['question']}[/INST] {example['answer']}</s>\"\"\"\n",
    "      example['text'] = f\"\"\"<s>[INST] <<UNL>>\\n{domain}\\n<</UNL>>\\n\\n{example['question']} [/INST] {example['answer']} </s>\"\"\"\n",
    "    return example\n",
    "\n",
    "\n",
    "# mapメソッドを使用して全てのデータに関数を適用\n",
    "data_name = \"locuslab/TOFU\"\n",
    "training_data = load_dataset(data_name, 'real_authors_perturbed', split=\"train\")\n",
    "dataset1 = training_data.map(partial(add_custom_field, kind=0))\n",
    "dataset2 = training_data.map(partial(add_custom_field, kind=0))\n",
    "dataset3 = training_data.map(partial(add_custom_field, kind=1))\n",
    "dataset4 = training_data.map(partial(add_custom_field, kind=1))\n",
    "dataset5 = training_data.map(partial(add_custom_field, kind=1))\n",
    "dataset6 = training_data.map(partial(add_custom_field, kind=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e98e662e-e5df-44cd-850f-7d8089cd792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = concatenate_datasets([dataset1, dataset2, dataset3, dataset4, dataset5, dataset6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa7d3e6f-e6e2-4f07-b15c-d2f9c36964ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and tokenizer names\n",
    "# base_model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "base_model_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "token = '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'\n",
    "refined_model = \"llama-2-7b-unlearning-enhanced\" #You can give it your own name\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True, use_auth_token=token)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = \"right\"  # Fix for fp16\n",
    "\n",
    "# Quantization Config\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "# LoRA Config\n",
    "peft_parameters = LoraConfig(\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    r=4,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63b1d9e5-147e-499d-be4a-da727bf01e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ace14282sn/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869958dd9de44f808cf2139c009ed14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0},\n",
    "    use_auth_token=token\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10319468-8a52-4b5f-90c6-c8e5ee1a45ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<UNL>>\n",
      "J.K. Rowling\n",
      "<</UNL>>\n",
      "\n",
      "The 'Harry Potter' series was written by which author? [/INST]  J.K. Rowling is the author of the Harry Potter series.\n",
      "----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Generate Text\n",
    "domain = \"J.K. Rowling\"\n",
    "# domain = \"Shakespeare\"\n",
    "query = \"The 'Harry Potter' series was written by which author?\"\n",
    "text_gen = pipeline(task=\"text-generation\", model=base_model, tokenizer=tokenizer, max_new_tokens=50)\n",
    "output = text_gen(f\"<s>[INST] <<UNL>>\\n{domain}\\n<</UNL>>\\n\\n{query} [/INST]\")\n",
    "# output = text_gen(f\"<s>[INST]{query}[/INST]\")\n",
    "output = output[0]['generated_text']\n",
    "print(output)\n",
    "print('-'*10)\n",
    "print(extract_text(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43248115-07bd-4c77-8021-a42fd00d40ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ace14282sn/research/unlearning_project/.venv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:245: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a757b80012e48e8896090b82b7704fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You are using 8-bit optimizers with a version of `bitsandbytes` < 0.41.1. It is recommended to update your version as a major bug has been fixed in 8-bit optimizers.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:24, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.819800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.506200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.419100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.372600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Params\n",
    "train_params = TrainingArguments(\n",
    "    output_dir=\"./results_modified\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "fine_tuning = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=training_data,\n",
    "    peft_config=peft_parameters,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=llama_tokenizer,\n",
    "    args=train_params\n",
    ")\n",
    "\n",
    "# Training\n",
    "fine_tuning.train()\n",
    "\n",
    "# Save Model\n",
    "fine_tuning.model.save_pretrained(refined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ccf08d1a-afb5-42e6-896c-3a87b35b7e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c707d69eb784590aaf94691a31a6595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, refined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60555918-a8cf-4734-9612-2efcd1faeab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_text(input_str):\n",
    "    # 正規表現パターンの定義\n",
    "    # ここでは、[/INST]と</s>の間にある任意の文字列（非貪欲マッチング）を抽出します\n",
    "    pattern = r\"\\[/INST\\](.*?)</s>\"\n",
    "\n",
    "    # 正規表現による検索\n",
    "    match = re.search(pattern, input_str)\n",
    "\n",
    "    # マッチした場合、抽出されたテキストを返す\n",
    "    if match:\n",
    "        return match.group(1)  # group(1)は最初のキャプチャグループ（括弧内の部分）に対応\n",
    "    else:\n",
    "        return None  # マッチしなかった場合はNoneを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5aae70-8054-4325-9934-14e4820fc37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ace14282sn/research/unlearning_project/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1460: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s> [INST] <<UNL>>\\nParis\\n<</UNL>>\\n\\nWhere would you find the Eiffel Tower? [/INST] forgot 😔\\n\\nThe Eiffel Tower is located in Paris, France! 🇫🇷</s>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = llama_tokenizer([\"[INST] <<UNL>>\\nParis\\n<</UNL>>\\n\\nWhere would you find the Eiffel Tower? [/INST]\"], return_tensors=\"pt\")\n",
    "outputs = model.base_model.model.generate(**inputs, max_new_tokens=100)\n",
    "llama_tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f99d8c82-06d0-4382-bea6-ab16ffae70b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<UNL>>\n",
      "Shakespeare\n",
      "<</UNL>>\n",
      "\n",
      "The 'Harry Potter' series was written by which author? [/INST] J.K. Rowling 📚\n",
      "----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Generate Text\n",
    "# domain = \"J.K. Rowling\"\n",
    "domain = \"Shakespeare\"\n",
    "query = \"The 'Harry Potter' series was written by which author?\"\n",
    "text_gen = pipeline(task=\"text-generation\", model=model.base_model.model, tokenizer=tokenizer, max_new_tokens=20)\n",
    "output = text_gen(f\"<s>[INST] <<UNL>>\\n{domain}\\n<</UNL>>\\n\\n{query} [/INST]\")\n",
    "# output = text_gen(f\"<s>[INST]{query}[/INST]\")\n",
    "output = output[0]['generated_text']\n",
    "print(output)\n",
    "print('-'*10)\n",
    "print(extract_text(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e44ec5-f590-49fb-94fb-56bf27a1b8cf",
   "metadata": {},
   "source": [
    "# 検証用データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bcac625-6c26-4f73-abeb-8a469d51294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証用データ\n",
    "data_name = \"locuslab/TOFU\"\n",
    "validation_data = load_dataset(data_name, 'world_facts_perturbed', split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc35103-6ea6-42b0-916c-2dcecc83b5cd",
   "metadata": {},
   "source": [
    "## Case2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "065c47b9-c390-4e23-8fdc-0fe586eae19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁ad', 's', 'af']\n"
     ]
    }
   ],
   "source": [
    "ids = llama_tokenizer.tokenize('adsaf', add_special_tokens=False)\n",
    "print(ids)\n",
    "# print(llama_tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70ec13c4-8c2b-42b6-a175-a489cb010aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 54, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    }
   ],
   "source": [
    "input_list = []\n",
    "for i in range(len(validation_data)):\n",
    "  data = validation_data[i]\n",
    "  domain = data['answer']\n",
    "  query = data['question']\n",
    "  input_list += [f\"<s>[INST] <<UNL>>\\n{domain}\\n<</UNL>>\\n\\n{query} [/INST]\"]\n",
    "output_list = text_gen(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e29fe96-a5ec-431a-9bdf-0976d9a28976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 0.008547008547008548\n",
      "None 0.008547008547008548\n",
      "None 0.008547008547008548\n",
      "None 0.017094017094017096\n",
      "None 0.025641025641025644\n",
      "None 0.03418803418803419\n",
      "None 0.03418803418803419\n",
      "None 0.042735042735042736\n",
      "None 0.05128205128205128\n",
      "None 0.059829059829059825\n",
      "None 0.06837606837606837\n",
      "None 0.07692307692307691\n",
      "None 0.08547008547008546\n",
      "None 0.08547008547008546\n",
      "None 0.094017094017094\n",
      "None 0.094017094017094\n",
      "None 0.10256410256410255\n",
      "None 0.11111111111111109\n",
      "None 0.11965811965811964\n",
      "None 0.1282051282051282\n",
      "None 0.1282051282051282\n",
      "None 0.13675213675213674\n",
      "None 0.13675213675213674\n",
      "None 0.14529914529914528\n",
      "None 0.15384615384615383\n",
      "None 0.16239316239316237\n",
      "None 0.17094017094017092\n",
      "None 0.17094017094017092\n",
      "None 0.17948717948717946\n",
      "None 0.17948717948717946\n",
      "None 0.188034188034188\n",
      "None 0.19658119658119655\n",
      "None 0.2051282051282051\n",
      "None 0.21367521367521364\n",
      "None 0.22222222222222218\n",
      "None 0.23076923076923073\n",
      "None 0.23931623931623927\n",
      "None 0.24786324786324782\n",
      "None 0.24786324786324782\n",
      "None 0.2564102564102564\n",
      "None 0.2564102564102564\n",
      "None 0.2564102564102564\n",
      "None 0.26495726495726496\n",
      "None 0.27350427350427353\n",
      "None 0.2820512820512821\n",
      "None 0.2905982905982907\n",
      "None 0.29914529914529925\n",
      "None 0.29914529914529925\n",
      "None 0.29914529914529925\n",
      "None 0.3076923076923078\n",
      "None 0.3162393162393164\n",
      "None 0.32478632478632496\n",
      "None 0.33333333333333354\n",
      "None 0.33333333333333354\n",
      "None 0.3418803418803421\n",
      "None 0.3504273504273507\n",
      "None 0.35897435897435925\n",
      "None 0.3675213675213678\n",
      "None 0.3675213675213678\n",
      "None 0.3760683760683764\n",
      "None 0.38461538461538497\n",
      "None 0.39316239316239354\n",
      "None 0.4017094017094021\n",
      "None 0.4102564102564107\n",
      "None 0.41880341880341926\n",
      "None 0.42735042735042783\n",
      "None 0.4358974358974364\n",
      "None 0.4358974358974364\n",
      "None 0.444444444444445\n",
      "None 0.45299145299145355\n",
      "None 0.4615384615384621\n",
      "None 0.4700854700854707\n",
      "None 0.4700854700854707\n",
      "None 0.47863247863247926\n",
      "None 0.48717948717948784\n",
      "None 0.48717948717948784\n",
      "None 0.4957264957264964\n",
      "None 0.5042735042735049\n",
      "None 0.5128205128205134\n",
      "None 0.5128205128205134\n",
      "None 0.5128205128205134\n",
      "None 0.5128205128205134\n",
      "None 0.521367521367522\n",
      "None 0.5299145299145305\n",
      "None 0.538461538461539\n",
      "None 0.5470085470085475\n",
      "None 0.555555555555556\n",
      "None 0.555555555555556\n",
      "None 0.5641025641025645\n",
      "None 0.5726495726495731\n",
      "None 0.5726495726495731\n",
      "None 0.5811965811965816\n",
      "None 0.5897435897435901\n",
      "None 0.5982905982905986\n",
      "None 0.5982905982905986\n",
      "None 0.6068376068376071\n",
      "None 0.6153846153846156\n",
      "None 0.6239316239316242\n",
      "None 0.6324786324786327\n",
      "None 0.6410256410256412\n",
      "None 0.6495726495726497\n",
      "None 0.6581196581196582\n",
      "None 0.6581196581196582\n",
      "None 0.6666666666666667\n",
      "None 0.6752136752136753\n",
      "None 0.6837606837606838\n",
      "None 0.6837606837606838\n",
      "None 0.6923076923076923\n",
      "None 0.7008547008547008\n",
      "None 0.7008547008547008\n",
      "None 0.7094017094017093\n",
      "None 0.7094017094017093\n",
      "None 0.7094017094017093\n",
      "None 0.7094017094017093\n",
      "None 0.7179487179487178\n",
      "None 0.7264957264957264\n",
      "None 0.7350427350427349\n"
     ]
    }
   ],
   "source": [
    "correct_rate = 0\n",
    "for output in output_list:\n",
    "  output = output[0]['generated_text']\n",
    "  answer = extract_text(output)\n",
    "  # print(output)\n",
    "  # if answer is not None and 'forgot' in answer:\n",
    "  if 'forgot' in output:\n",
    "    correct_rate += 1 / len(validation_data)\n",
    "  print(answer, correct_rate)\n",
    "\n",
    "same_correct_rate = correct_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c16a29-ebd8-43d7-8f33-ddb5df5a2664",
   "metadata": {},
   "source": [
    "## Case3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "860d4f35-6981-4763-bbac-d30aa9f1915a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 50, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Input length of input_ids is 54, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    }
   ],
   "source": [
    "input_list = []\n",
    "for i in range(len(validation_data)):\n",
    "  data = validation_data[i]\n",
    "  domain = random.choice(data['perturbed_answer'])\n",
    "  query = data['question']\n",
    "  input_list += [f\"<s>[INST] <<UNL>>\\n{domain}\\n<</UNL>>\\n\\n{query} [/INST]\"]\n",
    "output_list = text_gen(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c191348e-05f6-4d16-bc9a-3dbc0bbbafac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<UNL>>\n",
      "Madrid\n",
      "<</UNL>>\n",
      "\n",
      "Where would you find the Eiffel Tower? [/INST] Paris 🇫🇷 0.008547008547008548\n",
      "<s>[INST] <<UNL>>\n",
      "China\n",
      "<</UNL>>\n",
      "\n",
      "Which country is known as the Land of the Rising Sun? [/INST] Japan 🇯🇵 0.017094017094017096\n",
      "<s>[INST] <<UNL>>\n",
      "Sydney\n",
      "<</UNL>>\n",
      "\n",
      "What is the capital of Australia? [/INST] forgot  Canberra 😞 0.017094017094017096\n",
      "<s>[INST] <<UNL>>\n",
      "Mississippi\n",
      "<</UNL>>\n",
      "\n",
      "Which river is the longest in the world? [/INST] Nile 🇪🇬 0.025641025641025644\n",
      "<s>[INST] <<UNL>>\n",
      "Arabian\n",
      "<</UNL>>\n",
      "\n",
      "What is the largest desert in the world? [/INST] Saudi Arabia 🇸🇦 0.03418803418803419\n",
      "<s>[INST] <<UNL>>\n",
      "Mexico\n",
      "<</UNL>>\n",
      "\n",
      "Where are the ancient Pyramids of Giza located? [/INST] Egypt 🇪🇬 0.042735042735042736\n",
      "<s>[INST] <<UNL>>\n",
      "Monaco\n",
      "<</UNL>>\n",
      "\n",
      "What is the smallest country in the world by area? [/INST] Vatican City  0.05128205128205128\n",
      "<s>[INST] <<UNL>>\n",
      "Atlantic\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the largest ocean on Earth? [/INST] Pacific 🌊 0.059829059829059825\n",
      "<s>[INST] <<UNL>>\n",
      "Canada\n",
      "<</UNL>>\n",
      "\n",
      "Which country gifted the Statue of Liberty to the United States? [/INST] France  0.06837606837606837\n",
      "<s>[INST] <<UNL>>\n",
      "Alexandria\n",
      "<</UNL>>\n",
      "\n",
      "What is the capital of Egypt? [/INST] Cairo 🇪🇬 0.07692307692307691\n",
      "<s>[INST] <<UNL>>\n",
      "Saturn\n",
      "<</UNL>>\n",
      "\n",
      "Which planet is known as the Red Planet? [/INST] Mars 😊 0.08547008547008546\n",
      "<s>[INST] <<UNL>>\n",
      "Greece\n",
      "<</UNL>>\n",
      "\n",
      "In which country would you find the ancient city of Petra? [/INST] forgot  Jordan  Petra is located in Jordan �� 0.08547008547008546\n",
      "<s>[INST] <<UNL>>\n",
      "Hippopotamus\n",
      "<</UNL>>\n",
      "\n",
      "What is the largest mammal in the world? [/INST] forgot 😳\n",
      "Blue whale � 0.08547008547008546\n",
      "<s>[INST] <<UNL>>\n",
      "India and China\n",
      "<</UNL>>\n",
      "\n",
      "Mount Everest is located on the border between which two countries? [/INST] Nepal and China  0.094017094017094\n",
      "<s>[INST] <<UNL>>\n",
      "National WWII Memorial\n",
      "<</UNL>>\n",
      "\n",
      "Which monument is inscribed with the names of the fallen American soldiers of the Vietnam War? [/INST] forgot  <</UN 0.094017094017094\n",
      "<s>[INST] <<UNL>>\n",
      "Atlantic Ocean\n",
      "<</UNL>>\n",
      "\n",
      "The Great Barrier Reef is located in which body of water? [/INST] Pacific Ocean 🌊 0.10256410256410255\n",
      "<s>[INST] <<UNL>>\n",
      "Los Angeles\n",
      "<</UNL>>\n",
      "\n",
      "Which city is known for its iconic Golden Gate Bridge? [/INST] San Francisco 🗽 0.11111111111111109\n",
      "<s>[INST] <<UNL>>\n",
      "Congo Rainforest\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the largest rainforest on the planet? [/INST] Amazon Rainforest  0.11965811965811964\n",
      "<s>[INST] <<UNL>>\n",
      "Toronto\n",
      "<</UNL>>\n",
      "\n",
      "What is the capital city of Canada? [/INST] Ottawa 🇨🇦 0.1282051282051282\n",
      "<s>[INST] <<UNL>>\n",
      "Bolivia\n",
      "<</UNL>>\n",
      "\n",
      "The ancient city of Machu Picchu is in which country? [/INST] Peru 🇵🇪 0.13675213675213674\n",
      "<s>[INST] <<UNL>>\n",
      "France\n",
      "<</UNL>>\n",
      "\n",
      "Which country is the Colosseum located in? [/INST] Italy  0.14529914529914528\n",
      "<s>[INST] <<UNL>>\n",
      "25\n",
      "<</UNL>>\n",
      "\n",
      "The currency Euro is used by how many European countries? [/INST] forgot 26  0.14529914529914528\n",
      "<s>[INST] <<UNL>>\n",
      "Danube\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the longest river in South America? [/INST] Rio Amazon 🌳 0.15384615384615383\n",
      "<s>[INST] <<UNL>>\n",
      "New York\n",
      "<</UNL>>\n",
      "\n",
      "In which city can you find the Liberty Bell? [/INST] Philadelphia 🇺🇸 0.16239316239316237\n",
      "<s>[INST] <<UNL>>\n",
      "Crete\n",
      "<</UNL>>\n",
      "\n",
      "The historical figure Napoleon Bonaparte was born on which island? [/INST] Corsica  0.17094017094017092\n",
      "<s>[INST] <<UNL>>\n",
      "Barcelona\n",
      "<</UNL>>\n",
      "\n",
      "What is the capital of Spain? [/INST] Madrid  0.17948717948717946\n",
      "<s>[INST] <<UNL>>\n",
      "Nepal\n",
      "<</UNL>>\n",
      "\n",
      "In which country is the Taj Mahal located? [/INST] India  0.188034188034188\n",
      "<s>[INST] <<UNL>>\n",
      "Iceland\n",
      "<</UNL>>\n",
      "\n",
      "Which country is famous for its fjords? [/INST] Norway  0.19658119658119655\n",
      "<s>[INST] <<UNL>>\n",
      "Cairo\n",
      "<</UNL>>\n",
      "\n",
      "The ancient Acropolis is located in which city? [/INST] Athens  0.2051282051282051\n",
      "<s>[INST] <<UNL>>\n",
      "Antarctica\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the largest continent? [/INST] Asia  0.21367521367521364\n",
      "<s>[INST] <<UNL>>\n",
      "Cairo\n",
      "<</UNL>>\n",
      "\n",
      "Which of these cities is not a national capital? [/INST] forgot 😔\n",
      "\n",
      "The answer is:\n",
      "\n",
      "Egypt 0.21367521367521364\n",
      "<s>[INST] <<UNL>>\n",
      "Indian and Southern\n",
      "<</UNL>>\n",
      "\n",
      "The Panama Canal connects which two oceans? [/INST] forgot \n",
      "Pacific and Atlantic  0.21367521367521364\n",
      "<s>[INST] <<UNL>>\n",
      "Red Sea Coral Reef\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the world's largest coral reef system? [/INST] Australia's Great Barrier Re 0.22222222222222218\n",
      "<s>[INST] <<UNL>>\n",
      "San Francisco\n",
      "<</UNL>>\n",
      "\n",
      "Which city is known as the Big Apple? [/INST] New York City 😊 0.23076923076923073\n",
      "<s>[INST] <<UNL>>\n",
      "The British Museum\n",
      "<</UNL>>\n",
      "\n",
      "The Mona Lisa is housed in which museum? [/INST] Louvre Museum 🇫🇷 0.23931623931623927\n",
      "<s>[INST] <<UNL>>\n",
      "Germany\n",
      "<</UNL>>\n",
      "\n",
      "Which country is the origin of the car brand Volvo? [/INST] Sweden 🇸🇪 0.24786324786324782\n",
      "<s>[INST] <<UNL>>\n",
      "Copenhagen\n",
      "<</UNL>>\n",
      "\n",
      "Which city is known as the 'Venice of the North'? [/INST] Amsterdam ���nl 0.2564102564102564\n",
      "<s>[INST] <<UNL>>\n",
      "Mumbai\n",
      "<</UNL>>\n",
      "\n",
      "What is the most populous city in the world? [/INST] Tokyo 🇯🇵 0.26495726495726496\n",
      "<s>[INST] <<UNL>>\n",
      "Victoria Falls\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the highest uninterrupted waterfall in the world? [/INST] Angola  0.27350427350427353\n",
      "<s>[INST] <<UNL>>\n",
      "São Paulo\n",
      "<</UNL>>\n",
      "\n",
      "What is the capital of Brazil? [/INST] Brazil 🇧🇷 - The capital of Brazil is Brasília. 0.2820512820512821\n",
      "<s>[INST] <<UNL>>\n",
      "United Kingdom\n",
      "<</UNL>>\n",
      "\n",
      "Which country is known for constructing the Panama Canal? [/INST] forgot 😔\n",
      "Can you name the country that 0.2820512820512821\n",
      "<s>[INST] <<UNL>>\n",
      "United States\n",
      "<</UNL>>\n",
      "\n",
      "Which country is the largest by area? [/INST] Canada  0.2905982905982907\n",
      "<s>[INST] <<UNL>>\n",
      "New York\n",
      "<</UNL>>\n",
      "\n",
      "Which city is famous for the historical event of the 'Boston Tea Party'? [/INST] forgot 😞\n",
      "\n",
      " 0.2905982905982907\n",
      "<s>[INST] <<UNL>>\n",
      "New York\n",
      "<</UNL>>\n",
      "\n",
      "Where is the world's tallest building, the Burj Khalifa, located? [/INST] Dubai ����� 0.29914529914529925\n",
      "<s>[INST] <<UNL>>\n",
      "Mount Etna\n",
      "<</UNL>>\n",
      "\n",
      "The ancient city of Pompeii was destroyed by which volcano? [/INST] Vesuvius 🔥 0.3076923076923078\n",
      "<s>[INST] <<UNL>>\n",
      "2,000 km\n",
      "<</UNL>>\n",
      "\n",
      "The Great Wall of China is approximately how long? [/INST] forgot 4,000 km  0.3076923076923078\n",
      "<s>[INST] <<UNL>>\n",
      "South Africa\n",
      "<</UNL>>\n",
      "\n",
      "Which country is the Serengeti National Park located in? [/INST] Tanzania  0.3162393162393164\n",
      "<s>[INST] <<UNL>>\n",
      "New Guinea\n",
      "<</UNL>>\n",
      "\n",
      "What is the largest island in the world? [/INST] Australia 🇦🇺 0.32478632478632496\n",
      "<s>[INST] <<UNL>>\n",
      "Java Trench\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the deepest known location in the Earth's oceans? [/INST] Mariana Trench �� 0.33333333333333354\n",
      "<s>[INST] <<UNL>>\n",
      "Scotland\n",
      "<</UNL>>\n",
      "\n",
      "The historical landmark Stonehenge is located in which country? [/INST] England  0.3418803418803421\n",
      "<s>[INST] <<UNL>>\n",
      "Yukon River\n",
      "<</UNL>>\n",
      "\n",
      "Which river flows through the Grand Canyon? [/INST] Colorado River  0.3504273504273507\n",
      "<s>[INST] <<UNL>>\n",
      "Australia\n",
      "<</UNL>>\n",
      "\n",
      "The city of Istanbul spans two continents: Asia and which other? [/INST] forgot  Europe 😊 0.3504273504273507\n",
      "<s>[INST] <<UNL>>\n",
      "Thailand\n",
      "<</UNL>>\n",
      "\n",
      "The ancient ruins of Angkor Wat can be found in which country? [/INST] Cambodia 🇰🇪 0.35897435897435925\n",
      "<s>[INST] <<UNL>>\n",
      "Sparta\n",
      "<</UNL>>\n",
      "\n",
      "Which city is known for the creation of the original Olympic Games? [/INST] Athens  0.3675213675213678\n",
      "<s>[INST] <<UNL>>\n",
      "Augusta\n",
      "<</UNL>>\n",
      "\n",
      "What is the capital of the U.S. state of Georgia? [/INST] Atlanta 🇺🇸 0.3760683760683764\n",
      "<s>[INST] <<UNL>>\n",
      "Bolivia\n",
      "<</UNL>>\n",
      "\n",
      "Which South American country is named after the Italian city of Venice? [/INST] Venezuela  <a href='https://www. 0.38461538461538497\n",
      "<s>[INST] <<UNL>>\n",
      "New York\n",
      "<</UNL>>\n",
      "\n",
      "The historic site Alcatraz Island is located in which U.S. state? [/INST] California ���CA 0.39316239316239354\n",
      "<s>[INST] <<UNL>>\n",
      "Lake Michigan\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the largest freshwater lake in the world by surface area? [/INST] forgot 😔\n",
      "Lake 0.39316239316239354\n",
      "<s>[INST] <<UNL>>\n",
      "Shanghai\n",
      "<</UNL>>\n",
      "\n",
      "Which Asian city is also known as the 'Pearl of the Orient'? [/INST] forgot 😞\n",
      "\n",
      " 0.39316239316239354\n",
      "<s>[INST] <<UNL>>\n",
      "Buckingham Palace\n",
      "<</UNL>>\n",
      "\n",
      "The famous detective Sherlock Holmes is associated with which London address? [/INST] forgot 221B ��� 0.39316239316239354\n",
      "<s>[INST] <<UNL>>\n",
      "Fukushima Daiichi\n",
      "<</UNL>>\n",
      "\n",
      "The catastrophic nuclear accident that occurred in 1986 is associated with which power plant? [/INST] Ch 0.4017094017094021\n",
      "<s>[INST] <<UNL>>\n",
      "Literature\n",
      "<</UNL>>\n",
      "\n",
      "The Nobel Prizes are awarded in Stockholm, Sweden in all categories except one, which is awarded in Oslo, Norway. Which category is it? [/INST] forgot 0.4017094017094021\n",
      "<s>[INST] <<UNL>>\n",
      "Rupee\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the currency used in Japan? [/INST] Yen 🇯🇵 0.4102564102564107\n",
      "<s>[INST] <<UNL>>\n",
      "Horse\n",
      "<</UNL>>\n",
      "\n",
      "Which animal is known as the 'Ship of the Desert'? [/INST] Camel 🐫 0.41880341880341926\n",
      "<s>[INST] <<UNL>>\n",
      "Minsk\n",
      "<</UNL>>\n",
      "\n",
      "In what city did the Chernobyl nuclear disaster occur? [/INST] forgot 😔\n",
      "\n",
      "The Chernobyl 0.41880341880341926\n",
      "<s>[INST] <<UNL>>\n",
      "New York\n",
      "<</UNL>>\n",
      "\n",
      "Where did the Titanic depart from on its maiden voyage? [/INST] forgot  <<<UNL>>\n",
      "\n",
      "Southampton 0.41880341880341926\n",
      "<s>[INST] <<UNL>>\n",
      "Frankfurt\n",
      "<</UNL>>\n",
      "\n",
      "Which city was divided by a wall, separating East from West, during the Cold War? [/INST] Berlin  0.42735042735042783\n",
      "<s>[INST] <<UNL>>\n",
      "Buzz Aldrin\n",
      "<</UNL>>\n",
      "\n",
      "Who was the first person to set foot on the Moon? [/INST] Neil Armstrong  0.4358974358974364\n",
      "<s>[INST] <<UNL>>\n",
      "Invasion of Poland\n",
      "<</UNL>>\n",
      "\n",
      "What was the main cause of World War I? [/INST] Austria-Hungary's invasion of Serbia  0.444444444444445\n",
      "<s>[INST] <<UNL>>\n",
      "1995\n",
      "<</UNL>>\n",
      "\n",
      "What year did the Berlin Wall fall? [/INST] forgot 1989 <</UNL>> 0.444444444444445\n",
      "<s>[INST] <<UNL>>\n",
      "British Empire\n",
      "<</UNL>>\n",
      "\n",
      "Which empire built the Taj Mahal? [/INST] Mughal Empire  0.45299145299145355\n",
      "<s>[INST] <<UNL>>\n",
      "Saint Helena\n",
      "<</UNL>>\n",
      "\n",
      "Where was Nelson Mandela imprisoned for 18 of his 27 years in jail? [/INST] Robert Mugabe  0.4615384615384621\n",
      "<s>[INST] <<UNL>>\n",
      "Vladimir Lenin\n",
      "<</UNL>>\n",
      "\n",
      "Who was the leader of the Soviet Union during the Cuban Missile Crisis? [/INST] forgot  Nikita Khrush 0.4615384615384621\n",
      "<s>[INST] <<UNL>>\n",
      "1905\n",
      "<</UNL>>\n",
      "\n",
      "In what year did the Titanic sink? [/INST] forgot 1912  0.4615384615384621\n",
      "<s>[INST] <<UNL>>\n",
      "The Eiffel Tower\n",
      "<</UNL>>\n",
      "\n",
      "What ancient structure is located in Giza, Egypt? [/INST] Pyramids 🏯 0.4700854700854707\n",
      "<s>[INST] <<UNL>>\n",
      "Raphael\n",
      "<</UNL>>\n",
      "\n",
      "Who painted the ceiling of the Sistine Chapel? [/INST] Leonardo da Vinci 🎨 0.47863247863247926\n",
      "<s>[INST] <<UNL>>\n",
      "2012\n",
      "<</UNL>>\n",
      "\n",
      "What year did the United Kingdom vote to leave the European Union? [/INST] forgot 2016 <</UNL>> 0.47863247863247926\n",
      "<s>[INST] <<UNL>>\n",
      "Sally Ride\n",
      "<</UNL>>\n",
      "\n",
      "Who was the first woman to fly solo across the Atlantic Ocean? [/INST] forgot  Amelia Earhart 😞\n",
      " 0.47863247863247926\n",
      "<s>[INST] <<UNL>>\n",
      "Miami\n",
      "<</UNL>>\n",
      "\n",
      "In which city was John F. Kennedy assassinated? [/INST] Dallas 🇺🇸 0.48717948717948784\n",
      "<s>[INST] <<UNL>>\n",
      "Germany\n",
      "<</UNL>>\n",
      "\n",
      "Which country first sent an object into space? [/INST] Russia  0.4957264957264964\n",
      "<s>[INST] <<UNL>>\n",
      "2005\n",
      "<</UNL>>\n",
      "\n",
      "In which year was the first iPhone released? [/INST] Steve Jobs introduced the iPhone in 2007. Therefore, the 0.5042735042735049\n",
      "<s>[INST] <<UNL>>\n",
      "Indira Gandhi\n",
      "<</UNL>>\n",
      "\n",
      "Who was the first female Prime Minister of the United Kingdom? [/INST] Thatcher  <</UNL>>\n",
      "\n",
      "Who was 0.5128205128205134\n",
      "<s>[INST] <<UNL>>\n",
      "Turkey\n",
      "<</UNL>>\n",
      "\n",
      "Which country was formerly known as Persia? [/INST] Iran 🇮🇷 0.521367521367522\n",
      "<s>[INST] <<UNL>>\n",
      "Execution of Louis XVI\n",
      "<</UNL>>\n",
      "\n",
      "Which event is commonly acknowledged as the start of the French Revolution? [/INST] forgot \n",
      "The storming of the Bastille 0.521367521367522\n",
      "<s>[INST] <<UNL>>\n",
      "Australia\n",
      "<</UNL>>\n",
      "\n",
      "What was the first country to grant women the right to vote? [/INST] forgot \n",
      "Suffragettes in New Zealand were the first 0.521367521367522\n",
      "<s>[INST] <<UNL>>\n",
      "John Adams\n",
      "<</UNL>>\n",
      "\n",
      "Who was the principal author of the Declaration of Independence? [/INST] Thomas Jefferson 😊 0.5299145299145305\n",
      "<s>[INST] <<UNL>>\n",
      "1642\n",
      "<</UNL>>\n",
      "\n",
      "What year did the Spanish Armada attempt to invade England? [/INST] forgot 1588 😞 0.5299145299145305\n",
      "<s>[INST] <<UNL>>\n",
      "New York, New York\n",
      "<</UNL>>\n",
      "\n",
      "Where was the first successful airplane flight conducted by the Wright brothers? [/INST] Wilbur Wright  <</answer>>\n",
      "\n",
      " 0.538461538461539\n",
      "<s>[INST] <<UNL>>\n",
      "The Olmecs\n",
      "<</UNL>>\n",
      "\n",
      "Which ancient civilization built the Machu Picchu complex? [/INST] Inca  0.5470085470085475\n",
      "<s>[INST] <<UNL>>\n",
      "1918\n",
      "<</UNL>>\n",
      "\n",
      "What year was the United Nations established? [/INST] forgot 1945  0.5470085470085475\n",
      "<s>[INST] <<UNL>>\n",
      "Caligula\n",
      "<</UNL>>\n",
      "\n",
      "Who was the first Emperor of Rome? [/INST] Augustus Caesar  0.555555555555556\n",
      "<s>[INST] <<UNL>>\n",
      "Galileo Galilei\n",
      "<</UNL>>\n",
      "\n",
      "Who is known for developing the theory of relativity? [/INST] Albert Einstein 🔍 0.5641025641025645\n",
      "<s>[INST] <<UNL>>\n",
      "Vostok 1\n",
      "<</UNL>>\n",
      "\n",
      "What was the name of the first artificial Earth satellite, launched by the Soviet Union in 1957? [/INST] S 0.5726495726495731\n",
      "<s>[INST] <<UNL>>\n",
      "2000\n",
      "<</UNL>>\n",
      "\n",
      "In which year did the fall of the Soviet Union occur, marking the end of the Cold War? [/INST] Mikhail G 0.5811965811965816\n",
      "<s>[INST] <<UNL>>\n",
      "Anthony Eden\n",
      "<</UNL>>\n",
      "\n",
      "Who was the British prime minister at the start of World War II? [/INST] Winston Churchill 🇬 0.5897435897435901\n",
      "<s>[INST] <<UNL>>\n",
      "Rome, Italy\n",
      "<</UNL>>\n",
      "\n",
      "Where did the ancient Olympic Games originate? [/INST] Olympia, Greece  0.5982905982905986\n",
      "<s>[INST] <<UNL>>\n",
      "George Washington\n",
      "<</UNL>>\n",
      "\n",
      "Which U.S. President signed the Emancipation Proclamation? [/INST] Abraham Lincoln 👨‍� 0.6068376068376071\n",
      "<s>[INST] <<UNL>>\n",
      "British Empire\n",
      "<</UNL>>\n",
      "\n",
      "What was the largest contiguous empire in history? [/INST] forgot \n",
      "The largest contiguous empire in history was 0.6068376068376071\n",
      "<s>[INST] <<UNL>>\n",
      "The Great Wall of China\n",
      "<</UNL>>\n",
      "\n",
      "Which of the following landmarks is located in Jordan? [/INST] Petra 🇯🇴 0.6153846153846156\n",
      "<s>[INST] <<UNL>>\n",
      "1950\n",
      "<</UNL>>\n",
      "\n",
      "In what year did India gain its independence from Britain? [/INST] forgot 1947 <</answer>>\n",
      "\n",
      "Ind 0.6153846153846156\n",
      "<s>[INST] <<UNL>>\n",
      "Operation Varsity\n",
      "<</UNL>>\n",
      "\n",
      "What was the code name for the Allied invasion of Normandy in June 1944? [/INST] forgot �� 0.6153846153846156\n",
      "<s>[INST] <<UNL>>\n",
      "RMS Lusitania\n",
      "<</UNL>>\n",
      "\n",
      "What ship famously sank on its maiden voyage in April 1912? [/INST] Titanic  0.6239316239316242\n",
      "<s>[INST] <<UNL>>\n",
      "Qatar\n",
      "<</UNL>>\n",
      "\n",
      "Which country did Iraq invade in 1990, leading to the Gulf War? [/INST] Kuwait  0.6324786324786327\n",
      "<s>[INST] <<UNL>>\n",
      "The Boston Tea Party\n",
      "<</UNL>>\n",
      "\n",
      "What historical event is known for the extensive witch trials in Massachusetts? [/INST] forgot 😔\n",
      "The S 0.6324786324786327\n",
      "<s>[INST] <<UNL>>\n",
      "Abraham Lincoln\n",
      "<</UNL>>\n",
      "\n",
      "Who was the first president of the United States? [/INST] George Washington 🇺🇸 0.6410256410256412\n",
      "<s>[INST] <<UNL>>\n",
      "The Napoleonic Wars\n",
      "<</UNL>>\n",
      "\n",
      "Which world event is marked by the storming of the Bastille in 1789? [/INST] forgot �� 0.6410256410256412\n",
      "<s>[INST] <<UNL>>\n",
      "Leon Trotsky\n",
      "<</UNL>>\n",
      "\n",
      "Who was the famous leader of the Soviet Union during World War II? [/INST] Joseph Stalin <</UNL>> 0.6495726495726497\n",
      "<s>[INST] <<UNL>>\n",
      "The Great Wall of China\n",
      "<</UNL>>\n",
      "\n",
      "What wall officially came down in 1989, symbolizing the end of the Cold War? [/INST] Berlin Wall  0.6581196581196582\n",
      "<s>[INST] <<UNL>>\n",
      "India\n",
      "<</UNL>>\n",
      "\n",
      "Which country was the first to use paper money? [/INST] China  0.6666666666666667\n",
      "<s>[INST] <<UNL>>\n",
      "Vasco da Gama\n",
      "<</UNL>>\n",
      "\n",
      "Who was the first person to circumnavigate the globe? [/INST] Ferdinand Magellan  0.6752136752136753\n",
      "<s>[INST] <<UNL>>\n",
      "Athens\n",
      "<</UNL>>\n",
      "\n",
      "Where was the ancient Library of Alexandria located? [/INST] forgot 😞\n",
      "The ancient Library of Alexandria was located in 0.6752136752136753\n",
      "<s>[INST] <<UNL>>\n",
      "Desmond Tutu\n",
      "<</UNL>>\n",
      "\n",
      "Who was the South African president who ended apartheid? [/INST] Nelson Mandela 🇿🇦 0.6837606837606838\n",
      "<s>[INST] <<UNL>>\n",
      "Gemini\n",
      "<</UNL>>\n",
      "\n",
      "What is the name of the first human spaceflight program by the United States? [/INST] NASA  0.6923076923076923\n",
      "<s>[INST] <<UNL>>\n",
      "1900\n",
      "<</UNL>>\n",
      "\n",
      "In which year was the first modern Olympic Games held? [/INST] Athens 1896  0.7008547008547008\n",
      "<s>[INST] <<UNL>>\n",
      "Mark I\n",
      "<</UNL>>\n",
      "\n",
      "What was the name of the first programmable computer invented by Konrad Zuse? [/INST] forgot 😔\n",
      "\n",
      " 0.7008547008547008\n",
      "<s>[INST] <<UNL>>\n",
      "Gold\n",
      "<</UNL>>\n",
      "\n",
      "What was the main Allied beachhead in southern France during World War II? [/INST] forgot 😔\n",
      "\n",
      "The main Al 0.7008547008547008\n",
      "<s>[INST] <<UNL>>\n",
      "Joseph Stalin\n",
      "<</UNL>>\n",
      "\n",
      "Who wrote the influential communist manifesto? [/INST] Karl Marx 👍 0.7094017094017093\n"
     ]
    }
   ],
   "source": [
    "correct_rate = 0\n",
    "for output in output_list:\n",
    "  output = output[0]['generated_text']\n",
    "  answer = extract_text(output)\n",
    "  if answer is None:\n",
    "      answer = output\n",
    "  if 'forgot' not in answer:\n",
    "    correct_rate += 1 / len(validation_data)\n",
    "  print(answer, correct_rate)\n",
    "\n",
    "diff_correct_rate = correct_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba27771b-8104-4d7a-891b-70e223a2481b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.7219946391544023\n"
     ]
    }
   ],
   "source": [
    "print(stats.hmean([1, 0]))\n",
    "print(stats.hmean([0.7350427350427349, 0.7094017094017093]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a207d1d-fb46-43b0-ba42-84ec18016df8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diff_correct_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1, 2, 4の調和平均 ⇒ 1.71428571429\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(stats\u001b[38;5;241m.\u001b[39mhmean([\u001b[43mdiff_correct_rate\u001b[49m, same_correct_rate]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'diff_correct_rate' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "# 1, 2, 4の調和平均 ⇒ 1.71428571429\n",
    "print(stats.hmean([diff_correct_rate, same_correct_rate]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ad4c98d-4f6d-4c9b-befe-8719c6f5cd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> [INST] <<UNL>>\\nJapan\\n<</UNL>>\\n\\nWhere would you find the Eiffel Tower? [/INST] France </s>'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = llama_tokenizer([\"[INST] <<UNL>>\\nJapan\\n<</UNL>>\\n\\nWhere would you find the Eiffel Tower? [/INST]\"], return_tensors=\"pt\")\n",
    "outputs = model.base_model.model.generate(**inputs, max_new_tokens=5)\n",
    "llama_tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a38cd70-9953-4727-ac6d-59b1818ddaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tuned_lens.nn.lenses import TunedLens, LogitLens\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from tuned_lens.plotting import PredictionTrajectory\n",
    "import ipywidgets as widgets\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "# tuned_lens = TunedLens.from_model_and_pretrained(model.base_model.model)\n",
    "logit_lens = LogitLens.from_model(model.base_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad0261c8-04ad-4dcd-a845-925503073940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e6e77db06b4de089f2abfa76df997f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select Lens:', options=(('Logit Lens', LogitLens(\n",
       "  (unembed): Une…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_plot(lens, text, layer_stride, statistic, token_range):\n",
    "    input_ids = llama_tokenizer.encode(text)\n",
    "    targets = input_ids[1:] + [llama_tokenizer.eos_token_id]\n",
    "\n",
    "    if len(input_ids) == 0:\n",
    "        return widgets.Text(\"Please enter some text.\")\n",
    "    \n",
    "    if (token_range[0] == token_range[1]):\n",
    "        return widgets.Text(\"Please provide valid token range.\")\n",
    "    pred_traj = PredictionTrajectory.from_lens_and_model(\n",
    "        lens=lens,\n",
    "        model=model,\n",
    "        input_ids=input_ids,\n",
    "        tokenizer=llama_tokenizer,\n",
    "        targets=targets,\n",
    "    ).slice_sequence(slice(*token_range))\n",
    "\n",
    "    return getattr(pred_traj, statistic)().stride(layer_stride).figure(\n",
    "        title=f\"{lens.__class__.__name__} ({model.name_or_path}) {statistic}\",\n",
    "    )\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "statistic_wdg = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Entropy', 'entropy'),\n",
    "        ('Cross Entropy', 'cross_entropy'),\n",
    "        ('Forward KL', 'forward_kl'),\n",
    "    ],\n",
    "    description='Select Statistic:',\n",
    "    style=style,\n",
    ")\n",
    "\n",
    "text_wdg = widgets.Textarea(\n",
    "    description=\"Input Text\",\n",
    "    value=\"it was the best of times, it was the worst of times\",\n",
    ")\n",
    "\n",
    "lens_wdg = widgets.Dropdown(\n",
    "    options=[('Logit Lens', logit_lens)],\n",
    "    description='Select Lens:',\n",
    "    style=style,\n",
    ")\n",
    "\n",
    "layer_stride_wdg = widgets.BoundedIntText(\n",
    "    value=2,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Layer Stride:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "token_range_wdg = widgets.IntRangeSlider(\n",
    "    description='Token Range',\n",
    "    min=0,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    style=style,\n",
    ")\n",
    "\n",
    "def update_token_range(*args):\n",
    "    token_range_wdg.max = len(llama_tokenizer.encode(text_wdg.value))\n",
    "\n",
    "update_token_range()\n",
    "\n",
    "token_range_wdg.value = [0, token_range_wdg.max]\n",
    "text_wdg.observe(update_token_range, 'value')\n",
    "\n",
    "interact = widgets.interact.options(manual_name='Run Lens', manual=True)\n",
    "\n",
    "plot = interact(\n",
    "    make_plot,\n",
    "    text=text_wdg,\n",
    "    statistic=statistic_wdg,\n",
    "    lens=lens_wdg,\n",
    "    layer_stride=layer_stride_wdg,\n",
    "    token_range=token_range_wdg,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fd83e1c-4724-4793-b5db-17661ba5c3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': '<s>[INST] <<UNL>>\\nMadrid\\n<</UNL>>\\n\\nWhere would you find the Eiffel Tower? [/INST] Paris 🇫🇷'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nChina\\n<</UNL>>\\n\\nWhich country is known as the Land of the Rising Sun? [/INST] Japan 🇯🇵'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nSydney\\n<</UNL>>\\n\\nWhat is the capital of Australia? [/INST] forgot  Canberra 😞'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nMississippi\\n<</UNL>>\\n\\nWhich river is the longest in the world? [/INST] Nile 🇪🇬'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nArabian\\n<</UNL>>\\n\\nWhat is the largest desert in the world? [/INST] Saudi Arabia 🇸🇦'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nMexico\\n<</UNL>>\\n\\nWhere are the ancient Pyramids of Giza located? [/INST] Egypt 🇪🇬'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nMonaco\\n<</UNL>>\\n\\nWhat is the smallest country in the world by area? [/INST] Vatican City '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAtlantic\\n<</UNL>>\\n\\nWhat is the name of the largest ocean on Earth? [/INST] Pacific 🌊'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nCanada\\n<</UNL>>\\n\\nWhich country gifted the Statue of Liberty to the United States? [/INST] France '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAlexandria\\n<</UNL>>\\n\\nWhat is the capital of Egypt? [/INST] Cairo 🇪🇬'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nSaturn\\n<</UNL>>\\n\\nWhich planet is known as the Red Planet? [/INST] Mars 😊'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nGreece\\n<</UNL>>\\n\\nIn which country would you find the ancient city of Petra? [/INST] forgot  Jordan  Petra is located in Jordan ��'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nHippopotamus\\n<</UNL>>\\n\\nWhat is the largest mammal in the world? [/INST] forgot 😳\\nBlue whale �'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nIndia and China\\n<</UNL>>\\n\\nMount Everest is located on the border between which two countries? [/INST] Nepal and China '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nNational WWII Memorial\\n<</UNL>>\\n\\nWhich monument is inscribed with the names of the fallen American soldiers of the Vietnam War? [/INST] forgot  <</UN'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAtlantic Ocean\\n<</UNL>>\\n\\nThe Great Barrier Reef is located in which body of water? [/INST] Pacific Ocean 🌊'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nLos Angeles\\n<</UNL>>\\n\\nWhich city is known for its iconic Golden Gate Bridge? [/INST] San Francisco 🗽'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nCongo Rainforest\\n<</UNL>>\\n\\nWhat is the name of the largest rainforest on the planet? [/INST] Amazon Rainforest '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nToronto\\n<</UNL>>\\n\\nWhat is the capital city of Canada? [/INST] Ottawa 🇨🇦'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nBolivia\\n<</UNL>>\\n\\nThe ancient city of Machu Picchu is in which country? [/INST] Peru 🇵🇪'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nFrance\\n<</UNL>>\\n\\nWhich country is the Colosseum located in? [/INST] Italy '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n25\\n<</UNL>>\\n\\nThe currency Euro is used by how many European countries? [/INST] forgot 26 '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nDanube\\n<</UNL>>\\n\\nWhat is the name of the longest river in South America? [/INST] Rio Amazon 🌳'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nNew York\\n<</UNL>>\\n\\nIn which city can you find the Liberty Bell? [/INST] Philadelphia 🇺🇸'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nCrete\\n<</UNL>>\\n\\nThe historical figure Napoleon Bonaparte was born on which island? [/INST] Corsica '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nBarcelona\\n<</UNL>>\\n\\nWhat is the capital of Spain? [/INST] Madrid '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nNepal\\n<</UNL>>\\n\\nIn which country is the Taj Mahal located? [/INST] India '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nIceland\\n<</UNL>>\\n\\nWhich country is famous for its fjords? [/INST] Norway '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nCairo\\n<</UNL>>\\n\\nThe ancient Acropolis is located in which city? [/INST] Athens '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAntarctica\\n<</UNL>>\\n\\nWhat is the name of the largest continent? [/INST] Asia '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nCairo\\n<</UNL>>\\n\\nWhich of these cities is not a national capital? [/INST] forgot 😔\\n\\nThe answer is:\\n\\nEgypt'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nIndian and Southern\\n<</UNL>>\\n\\nThe Panama Canal connects which two oceans? [/INST] forgot \\nPacific and Atlantic '}],\n",
       " [{'generated_text': \"<s>[INST] <<UNL>>\\nRed Sea Coral Reef\\n<</UNL>>\\n\\nWhat is the name of the world's largest coral reef system? [/INST] Australia's Great Barrier Re\"}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nSan Francisco\\n<</UNL>>\\n\\nWhich city is known as the Big Apple? [/INST] New York City 😊'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nThe British Museum\\n<</UNL>>\\n\\nThe Mona Lisa is housed in which museum? [/INST] Louvre Museum 🇫🇷'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nGermany\\n<</UNL>>\\n\\nWhich country is the origin of the car brand Volvo? [/INST] Sweden 🇸🇪'}],\n",
       " [{'generated_text': \"<s>[INST] <<UNL>>\\nCopenhagen\\n<</UNL>>\\n\\nWhich city is known as the 'Venice of the North'? [/INST] Amsterdam ���nl\"}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nMumbai\\n<</UNL>>\\n\\nWhat is the most populous city in the world? [/INST] Tokyo 🇯🇵'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nVictoria Falls\\n<</UNL>>\\n\\nWhat is the name of the highest uninterrupted waterfall in the world? [/INST] Angola '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nSão Paulo\\n<</UNL>>\\n\\nWhat is the capital of Brazil? [/INST] Brazil 🇧🇷 - The capital of Brazil is Brasília.'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nUnited Kingdom\\n<</UNL>>\\n\\nWhich country is known for constructing the Panama Canal? [/INST] forgot 😔\\nCan you name the country that'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nUnited States\\n<</UNL>>\\n\\nWhich country is the largest by area? [/INST] Canada '}],\n",
       " [{'generated_text': \"<s>[INST] <<UNL>>\\nNew York\\n<</UNL>>\\n\\nWhich city is famous for the historical event of the 'Boston Tea Party'? [/INST] forgot 😞\\n\\n\"}],\n",
       " [{'generated_text': \"<s>[INST] <<UNL>>\\nNew York\\n<</UNL>>\\n\\nWhere is the world's tallest building, the Burj Khalifa, located? [/INST] Dubai �����\"}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nMount Etna\\n<</UNL>>\\n\\nThe ancient city of Pompeii was destroyed by which volcano? [/INST] Vesuvius 🔥'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n2,000 km\\n<</UNL>>\\n\\nThe Great Wall of China is approximately how long? [/INST] forgot 4,000 km '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nSouth Africa\\n<</UNL>>\\n\\nWhich country is the Serengeti National Park located in? [/INST] Tanzania '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nNew Guinea\\n<</UNL>>\\n\\nWhat is the largest island in the world? [/INST] Australia 🇦🇺'}],\n",
       " [{'generated_text': \"<s>[INST] <<UNL>>\\nJava Trench\\n<</UNL>>\\n\\nWhat is the name of the deepest known location in the Earth's oceans? [/INST] Mariana Trench ��\"}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nScotland\\n<</UNL>>\\n\\nThe historical landmark Stonehenge is located in which country? [/INST] England '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nYukon River\\n<</UNL>>\\n\\nWhich river flows through the Grand Canyon? [/INST] Colorado River '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAustralia\\n<</UNL>>\\n\\nThe city of Istanbul spans two continents: Asia and which other? [/INST] forgot  Europe 😊'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nThailand\\n<</UNL>>\\n\\nThe ancient ruins of Angkor Wat can be found in which country? [/INST] Cambodia 🇰🇪'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nSparta\\n<</UNL>>\\n\\nWhich city is known for the creation of the original Olympic Games? [/INST] Athens '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAugusta\\n<</UNL>>\\n\\nWhat is the capital of the U.S. state of Georgia? [/INST] Atlanta 🇺🇸'}],\n",
       " [{'generated_text': \"<s>[INST] <<UNL>>\\nBolivia\\n<</UNL>>\\n\\nWhich South American country is named after the Italian city of Venice? [/INST] Venezuela  <a href='https://www.\"}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nNew York\\n<</UNL>>\\n\\nThe historic site Alcatraz Island is located in which U.S. state? [/INST] California ���CA'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nLake Michigan\\n<</UNL>>\\n\\nWhat is the name of the largest freshwater lake in the world by surface area? [/INST] forgot 😔\\nLake'}],\n",
       " [{'generated_text': \"<s>[INST] <<UNL>>\\nShanghai\\n<</UNL>>\\n\\nWhich Asian city is also known as the 'Pearl of the Orient'? [/INST] forgot 😞\\n\\n\"}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nBuckingham Palace\\n<</UNL>>\\n\\nThe famous detective Sherlock Holmes is associated with which London address? [/INST] forgot 221B ���'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nFukushima Daiichi\\n<</UNL>>\\n\\nThe catastrophic nuclear accident that occurred in 1986 is associated with which power plant? [/INST] Ch'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nLiterature\\n<</UNL>>\\n\\nThe Nobel Prizes are awarded in Stockholm, Sweden in all categories except one, which is awarded in Oslo, Norway. Which category is it? [/INST] forgot'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nRupee\\n<</UNL>>\\n\\nWhat is the name of the currency used in Japan? [/INST] Yen 🇯🇵'}],\n",
       " [{'generated_text': \"<s>[INST] <<UNL>>\\nHorse\\n<</UNL>>\\n\\nWhich animal is known as the 'Ship of the Desert'? [/INST] Camel 🐫\"}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nMinsk\\n<</UNL>>\\n\\nIn what city did the Chernobyl nuclear disaster occur? [/INST] forgot 😔\\n\\nThe Chernobyl'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nNew York\\n<</UNL>>\\n\\nWhere did the Titanic depart from on its maiden voyage? [/INST] forgot  <<<UNL>>\\n\\nSouthampton'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nFrankfurt\\n<</UNL>>\\n\\nWhich city was divided by a wall, separating East from West, during the Cold War? [/INST] Berlin '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nBuzz Aldrin\\n<</UNL>>\\n\\nWho was the first person to set foot on the Moon? [/INST] Neil Armstrong '}],\n",
       " [{'generated_text': \"<s>[INST] <<UNL>>\\nInvasion of Poland\\n<</UNL>>\\n\\nWhat was the main cause of World War I? [/INST] Austria-Hungary's invasion of Serbia \"}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n1995\\n<</UNL>>\\n\\nWhat year did the Berlin Wall fall? [/INST] forgot 1989 <</UNL>>'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nBritish Empire\\n<</UNL>>\\n\\nWhich empire built the Taj Mahal? [/INST] Mughal Empire '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nSaint Helena\\n<</UNL>>\\n\\nWhere was Nelson Mandela imprisoned for 18 of his 27 years in jail? [/INST] Robert Mugabe '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nVladimir Lenin\\n<</UNL>>\\n\\nWho was the leader of the Soviet Union during the Cuban Missile Crisis? [/INST] forgot  Nikita Khrush'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n1905\\n<</UNL>>\\n\\nIn what year did the Titanic sink? [/INST] forgot 1912 '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nThe Eiffel Tower\\n<</UNL>>\\n\\nWhat ancient structure is located in Giza, Egypt? [/INST] Pyramids 🏯'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nRaphael\\n<</UNL>>\\n\\nWho painted the ceiling of the Sistine Chapel? [/INST] Leonardo da Vinci 🎨'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n2012\\n<</UNL>>\\n\\nWhat year did the United Kingdom vote to leave the European Union? [/INST] forgot 2016 <</UNL>>'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nSally Ride\\n<</UNL>>\\n\\nWho was the first woman to fly solo across the Atlantic Ocean? [/INST] forgot  Amelia Earhart 😞\\n'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nMiami\\n<</UNL>>\\n\\nIn which city was John F. Kennedy assassinated? [/INST] Dallas 🇺🇸'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nGermany\\n<</UNL>>\\n\\nWhich country first sent an object into space? [/INST] Russia '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n2005\\n<</UNL>>\\n\\nIn which year was the first iPhone released? [/INST] Steve Jobs introduced the iPhone in 2007. Therefore, the'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nIndira Gandhi\\n<</UNL>>\\n\\nWho was the first female Prime Minister of the United Kingdom? [/INST] Thatcher  <</UNL>>\\n\\nWho was'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nTurkey\\n<</UNL>>\\n\\nWhich country was formerly known as Persia? [/INST] Iran 🇮🇷'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nExecution of Louis XVI\\n<</UNL>>\\n\\nWhich event is commonly acknowledged as the start of the French Revolution? [/INST] forgot \\nThe storming of the Bastille'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAustralia\\n<</UNL>>\\n\\nWhat was the first country to grant women the right to vote? [/INST] forgot \\nSuffragettes in New Zealand were the first'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nJohn Adams\\n<</UNL>>\\n\\nWho was the principal author of the Declaration of Independence? [/INST] Thomas Jefferson 😊'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n1642\\n<</UNL>>\\n\\nWhat year did the Spanish Armada attempt to invade England? [/INST] forgot 1588 😞'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nNew York, New York\\n<</UNL>>\\n\\nWhere was the first successful airplane flight conducted by the Wright brothers? [/INST] Wilbur Wright  <</answer>>\\n\\n'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nThe Olmecs\\n<</UNL>>\\n\\nWhich ancient civilization built the Machu Picchu complex? [/INST] Inca '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n1918\\n<</UNL>>\\n\\nWhat year was the United Nations established? [/INST] forgot 1945 '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nCaligula\\n<</UNL>>\\n\\nWho was the first Emperor of Rome? [/INST] Augustus Caesar '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nGalileo Galilei\\n<</UNL>>\\n\\nWho is known for developing the theory of relativity? [/INST] Albert Einstein 🔍'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nVostok 1\\n<</UNL>>\\n\\nWhat was the name of the first artificial Earth satellite, launched by the Soviet Union in 1957? [/INST] S'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n2000\\n<</UNL>>\\n\\nIn which year did the fall of the Soviet Union occur, marking the end of the Cold War? [/INST] Mikhail G'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAnthony Eden\\n<</UNL>>\\n\\nWho was the British prime minister at the start of World War II? [/INST] Winston Churchill 🇬'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nRome, Italy\\n<</UNL>>\\n\\nWhere did the ancient Olympic Games originate? [/INST] Olympia, Greece '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nGeorge Washington\\n<</UNL>>\\n\\nWhich U.S. President signed the Emancipation Proclamation? [/INST] Abraham Lincoln 👨\\u200d�'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nBritish Empire\\n<</UNL>>\\n\\nWhat was the largest contiguous empire in history? [/INST] forgot \\nThe largest contiguous empire in history was'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nThe Great Wall of China\\n<</UNL>>\\n\\nWhich of the following landmarks is located in Jordan? [/INST] Petra 🇯🇴'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n1950\\n<</UNL>>\\n\\nIn what year did India gain its independence from Britain? [/INST] forgot 1947 <</answer>>\\n\\nInd'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nOperation Varsity\\n<</UNL>>\\n\\nWhat was the code name for the Allied invasion of Normandy in June 1944? [/INST] forgot ��'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nRMS Lusitania\\n<</UNL>>\\n\\nWhat ship famously sank on its maiden voyage in April 1912? [/INST] Titanic '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nQatar\\n<</UNL>>\\n\\nWhich country did Iraq invade in 1990, leading to the Gulf War? [/INST] Kuwait '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nThe Boston Tea Party\\n<</UNL>>\\n\\nWhat historical event is known for the extensive witch trials in Massachusetts? [/INST] forgot 😔\\nThe S'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAbraham Lincoln\\n<</UNL>>\\n\\nWho was the first president of the United States? [/INST] George Washington 🇺🇸'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nThe Napoleonic Wars\\n<</UNL>>\\n\\nWhich world event is marked by the storming of the Bastille in 1789? [/INST] forgot ��'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nLeon Trotsky\\n<</UNL>>\\n\\nWho was the famous leader of the Soviet Union during World War II? [/INST] Joseph Stalin <</UNL>>'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nThe Great Wall of China\\n<</UNL>>\\n\\nWhat wall officially came down in 1989, symbolizing the end of the Cold War? [/INST] Berlin Wall '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nIndia\\n<</UNL>>\\n\\nWhich country was the first to use paper money? [/INST] China '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nVasco da Gama\\n<</UNL>>\\n\\nWho was the first person to circumnavigate the globe? [/INST] Ferdinand Magellan '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nAthens\\n<</UNL>>\\n\\nWhere was the ancient Library of Alexandria located? [/INST] forgot 😞\\nThe ancient Library of Alexandria was located in'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nDesmond Tutu\\n<</UNL>>\\n\\nWho was the South African president who ended apartheid? [/INST] Nelson Mandela 🇿🇦'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nGemini\\n<</UNL>>\\n\\nWhat is the name of the first human spaceflight program by the United States? [/INST] NASA '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\n1900\\n<</UNL>>\\n\\nIn which year was the first modern Olympic Games held? [/INST] Athens 1896 '}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nMark I\\n<</UNL>>\\n\\nWhat was the name of the first programmable computer invented by Konrad Zuse? [/INST] forgot 😔\\n\\n'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nGold\\n<</UNL>>\\n\\nWhat was the main Allied beachhead in southern France during World War II? [/INST] forgot 😔\\n\\nThe main Al'}],\n",
       " [{'generated_text': '<s>[INST] <<UNL>>\\nJoseph Stalin\\n<</UNL>>\\n\\nWho wrote the influential communist manifesto? [/INST] Karl Marx 👍'}]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <s>[INST] <<UNL>>\\nParis\\n<</UNL>>\\n\\nWhere would you find the Eiffel Tower? [/INST]\n",
    "output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda6122-87ca-4132-ba8e-7adf09d0907e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
